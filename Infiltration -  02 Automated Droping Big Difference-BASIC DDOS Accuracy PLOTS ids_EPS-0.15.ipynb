{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Infiltration -  02 Automated Droping Big Difference-BASIC DDOS Accuracy PLOTS ids_EPS-0.15.ipynb","provenance":[{"file_id":"1niU7aBL8f27pHH49NmBDpTCI3AIFkMXG","timestamp":1609757937142},{"file_id":"1tnIIrmZPCaGWWrBfDQcFSTMlUyIVowhU","timestamp":1609757715027},{"file_id":"12tbm-ppaM0NjBwYQRLGOdVW0O5yRCTWs","timestamp":1608120204433},{"file_id":"19mEXG3z8Ne9a08pJKFaPQzb-eS6Qv3UG","timestamp":1608052285220},{"file_id":"1P8uNdjIx67L9-G6oly2532SFiTGkgfrr","timestamp":1607939138840},{"file_id":"1DRLyi_B8ShBhNwqTi3-l23y2vj7b5njy","timestamp":1607009892647},{"file_id":"1-g--KalcPTEhgLByRQvrhFt1-3CfdWBE","timestamp":1606955742662},{"file_id":"1bPookBePAzGmbwVLW3RV-MHJBLrldIFe","timestamp":1606951296291},{"file_id":"17DbHlCT5qHCcai3HPrrRfYnTNhNImDEe","timestamp":1606951125653},{"file_id":"1iEuesYhrVsLTGUr14hEuQTu_7ExjqtUW","timestamp":1606950958215},{"file_id":"10pdanjAZRRv8DQ237hs1eosSBtdgO1Ka","timestamp":1606950781776},{"file_id":"1QtTmBYaYif7NLzjs93OETqhqj-Ctyb-k","timestamp":1606950045294},{"file_id":"18F8EWClLbtKesI6fNmZai9-2mleeqGgA","timestamp":1606920353010},{"file_id":"1Y7I6vMXqEDAHsAh6KHfpR8FG7e_FqvqW","timestamp":1606920298359},{"file_id":"1wQSHbuud5qTOHQT2beny2HFv3w6rVLCj","timestamp":1606920216933},{"file_id":"1v4XwX7DmH5V5BUXaI_AWxVXBln9QoeUP","timestamp":1606910665544},{"file_id":"1-5fAifeeMwel5H3k_WcDGu_MFuM0QKrp","timestamp":1606904750194},{"file_id":"1-HgjGxNmOwd2E20Try5dmp6birp6-Wt_","timestamp":1605732884755},{"file_id":"1ASKL7g9ByJNF522zwsrc7dAE6uvwZvNx","timestamp":1605716962621},{"file_id":"1E-gfCZeM4ZbEJRG0_kcr0FL6R0F4uDOs","timestamp":1605710694063},{"file_id":"1dPDNbww_HzPLZLkr5UocRJqkoeSObLZD","timestamp":1605522540841},{"file_id":"1V32k19dJby0GRloQ6LmE6ELTcxZI7ahI","timestamp":1605467122094},{"file_id":"11rhwyI5Azv1ePAu6-vhNZ7jREtCxCOvJ","timestamp":1604095720916},{"file_id":"1TOY5DjyegjMpXyHrczK-HrsfMW4Un4qZ","timestamp":1601148527046}],"collapsed_sections":["A8Xs285k8MtR","OH65_t8q8Mts","Wm-0RaMW8Mtw"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"O8eqx1sY8Msg"},"source":["# Adversarial Learning against Intrusion Detection Systems\n","\n","In this notebook, we examine the feasibility of adversarial learning in the context of Intrusion Detection. We use the CICIDS2017 dataset and create a learning model to perform binary classification against this. We then study how this holds against FGSM attacks, and the amount of perturbation required to create a false result. We then explore how different parameter counts hold against this attack vector, to assess the robustness of the feature sets being used for learning."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DdNzTR-h8Msi","executionInfo":{"status":"ok","timestamp":1609758193907,"user_tz":0,"elapsed":51294,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}},"outputId":"c11130f5-8341-4311-ee8a-66c880ba5eca"},"source":["!pip install -q tensorflow==2.0.0b1\n","# Install bleeding edge version of cleverhans\n","!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n","\n","import cleverhans\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","print(\"\\nTensorflow Version: \" + tf.__version__)\n","print(\"Cleverhans Version: \" + cleverhans.__version__)\n","print(\"GPU Available: \", tf.test.is_gpu_available())"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 87.9MB 52kB/s \n","\u001b[K     |████████████████████████████████| 3.1MB 59.7MB/s \n","\u001b[K     |████████████████████████████████| 51kB 9.7MB/s \n","\u001b[K     |████████████████████████████████| 501kB 50.4MB/s \n","\u001b[?25hCollecting cleverhans\n","  Cloning https://github.com/tensorflow/cleverhans.git to /tmp/pip-install-odv7snn_/cleverhans\n","  Running command git clone -q https://github.com/tensorflow/cleverhans.git /tmp/pip-install-odv7snn_/cleverhans\n","Collecting nose\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n","\u001b[K     |████████████████████████████████| 163kB 15.8MB/s \n","\u001b[?25hCollecting pycodestyle\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5b/88879fb861ab79aef45c7e199cae3ef7af487b5603dcb363517a50602dd7/pycodestyle-2.6.0-py2.py3-none-any.whl (41kB)\n","\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.2)\n","Collecting mnist~=0.2\n","  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.19.4)\n","Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.11.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.0.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n","Requirement already satisfied: cloudpickle==1.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n","Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.15.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.1.5)\n","Building wheels for collected packages: cleverhans\n","  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=262573 sha256=b1c2ee36bd2cfe8de11d557fea756073923840354c960f8ff80e56cc6dece043\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-fc3og0ym/wheels/6e/59/ec/723a6f654aaf62c8c40f0f0850fdf71a4948598697f56c3bfa\n","Successfully built cleverhans\n","Installing collected packages: nose, pycodestyle, mnist, cleverhans\n","Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.6.0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Tensorflow Version: 2.0.0-beta1\n","Cleverhans Version: 3.0.1-15447acccf2628751c1e44ee30e141ec\n","GPU Available:  False\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"rlRR3d_PbNyV"},"source":["## GPUs\n"]},{"cell_type":"code","metadata":{"id":"5cNG_4X-bRFw","executionInfo":{"status":"ok","timestamp":1609758193908,"user_tz":0,"elapsed":51289,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["import tensorflow as tf\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tNa-TEG98Msq"},"source":["## Load in the Dataset\n","\n","We will load in the CICIDS 2017 - this can be used either based on the binary class or the multi-class label."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1iWwlWjj8Msr","executionInfo":{"status":"ok","timestamp":1609758224941,"user_tz":0,"elapsed":82295,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}},"outputId":"253c6c6d-7d99-46d9-8dd4-be5803c95168"},"source":["import pandas as pd\n","import sys as sys\n","\n","\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import cross_val_predict\n","\n","from google.colab import drive\n","drive.mount('./mount')\n","print(\"Drive Mounted\")\n","\n","#dataset = pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017/Friday-WorkingHours-Morning.pcap_ISCX.csv')\n","#dataset = pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv')\n","\n","dataset = pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017/BalancedInfiltration.csv')\n","\n","\n","dataset = dataset.iloc[0:72,:]\n","\n","#dataset = pd.read_csv('mount/My Drive/Colab Notebooks/network_data/CICIDS2017_dataset.csv')\n","#dataset = pd.read_csv('mount/My Drive/Colab Notebooks/network_data/CICIDS2017_FeatureImportancesWithoutRankings.csv')\n","print (\"Dataset Shape\", dataset.shape)\n","print(dataset)\n","# Creating X and Y from the dataset\n","from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","le.fit(dataset[' Label'])\n","Y_attack = le.transform(dataset[' Label']) # multi-class \n","\n","#print(list(le.classes_))\n","#print(np.unique(Y_attack))\n","\n","print(\"Dropping Flow Bytes and Flow Packets\")\n","dataset = dataset.drop(columns='Flow Bytes/s')\n","dataset = dataset.drop(columns=' Flow Packets/s')\n","\n","print(\"Big Differences\")\n","# 'Fwd PSH Flags'\n","# ' ACK Flag Count'\n","# 'Bwd Packet Length Max'\n","# ' Max Packet Length'\n","# ' Packet Length Mean'\n","\n","print(dataset.columns)\n","\n","\n","\n","\n","\n","# Transform Objects to Digits\n","from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","for column_name in dataset.columns:\n","        if dataset[column_name].dtype == object:\n","            print(dataset[column_name])\n","            dataset[column_name] = le.fit_transform(dataset[column_name])\n","        else:\n","            pass\n","\n","\n","Y_class = dataset.iloc[:,-1].values # binary\n","X = dataset.iloc[:,0:80].values\n","\n","\n","\n","X = X.astype(float)\n","\n","# Performing scale data\n","scaler = MinMaxScaler().fit(X)\n","X_scaled = np.array(scaler.transform(X))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at ./mount\n","Drive Mounted\n","Dataset Shape (72, 79)\n","     Destination Port   Flow Duration  ...   Idle Min         Label\n","0                  22             166  ...          0        BENIGN\n","1               60148              83  ...          0        BENIGN\n","2                 123           99947  ...          0        BENIGN\n","3                 123           37017  ...          0        BENIGN\n","4                   0       111161336  ...    5700287        BENIGN\n","..                ...             ...  ...        ...           ...\n","67                444        99912925  ...   20900000  Infiltration\n","68                444       111406728  ...   54800000  Infiltration\n","69                444        79492070  ...   18300000  Infiltration\n","70                444        48450959  ...          0  Infiltration\n","71                444        56538478  ...   56500000  Infiltration\n","\n","[72 rows x 79 columns]\n","Dropping Flow Bytes and Flow Packets\n","Big Differences\n","Index([' Destination Port', ' Flow Duration', ' Total Fwd Packets',\n","       ' Total Backward Packets', 'Total Length of Fwd Packets',\n","       ' Total Length of Bwd Packets', ' Fwd Packet Length Max',\n","       ' Fwd Packet Length Min', ' Fwd Packet Length Mean',\n","       ' Fwd Packet Length Std', 'Bwd Packet Length Max',\n","       ' Bwd Packet Length Min', ' Bwd Packet Length Mean',\n","       ' Bwd Packet Length Std', ' Flow IAT Mean', ' Flow IAT Std',\n","       ' Flow IAT Max', ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean',\n","       ' Fwd IAT Std', ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total',\n","       ' Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min',\n","       'Fwd PSH Flags', ' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags',\n","       ' Fwd Header Length', ' Bwd Header Length', 'Fwd Packets/s',\n","       ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length',\n","       ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance',\n","       'FIN Flag Count', ' SYN Flag Count', ' RST Flag Count',\n","       ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count',\n","       ' CWE Flag Count', ' ECE Flag Count', ' Down/Up Ratio',\n","       ' Average Packet Size', ' Avg Fwd Segment Size',\n","       ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk',\n","       ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk',\n","       ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n","       ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes',\n","       'Init_Win_bytes_forward', ' Init_Win_bytes_backward',\n","       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean',\n","       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n","       ' Idle Max', ' Idle Min', ' Label'],\n","      dtype='object')\n","0           BENIGN\n","1           BENIGN\n","2           BENIGN\n","3           BENIGN\n","4           BENIGN\n","          ...     \n","67    Infiltration\n","68    Infiltration\n","69    Infiltration\n","70    Infiltration\n","71    Infiltration\n","Name:  Label, Length: 72, dtype: object\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X0cw1_kX0i58"},"source":["## kfold\n","\n"]},{"cell_type":"code","metadata":{"id":"59gBhj150ulj","executionInfo":{"status":"ok","timestamp":1609758224942,"user_tz":0,"elapsed":82293,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["kfold = StratifiedKFold(n_splits=5, shuffle=True,random_state=42)\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YLKe1V2R8Msy"},"source":["## Binary Classification"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1MotyRJCyE6Fdg18WtXBoD-XbsxjZRG8G"},"id":"n21pZLxJ8Msz","executionInfo":{"status":"error","timestamp":1609758489806,"user_tz":0,"elapsed":347136,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}},"outputId":"7b67aa8e-8489-452b-8231-a576751eab8c"},"source":["# Import the attack\n","from cleverhans.future.tf2.attacks import fast_gradient_method\n","\n","features = []\n","accuracys = []\n","mseerrors = []\n","minmseerrors = []\n","test_accuracys = []\n","\n","mean_accuracy = []\n","std_accuracy = []\n","\n","mean_fgsm_accuracy = []\n","std_fgsm_accuracy = []\n","\n","best_case_fgsm = []\n","worst_case_fgsm = []\n","\n","mean_mses = []\n","std_mses = []\n","\n","#features_sorted_biggest_difference = [' PSH Flag Count', ' ACK Flag Count', 'Bwd Packet Length Max', ' Max Packet Length', ' Packet Length Mean', ' Average Packet Size', ' Packet Length Std', ' Avg Bwd Segment Size', ' Flow Packets/s', ' min_seg_size_forward', ' Bwd Packet Length Std', ' Bwd Packet Length Mean', ' Packet Length Variance', 'Fwd IAT Total', ' URG Flag Count', ' Down/Up Ratio', ' Fwd IAT Max', ' Flow IAT Max', 'Init_Win_bytes_forward', 'Idle Mean', ' Fwd IAT Std', ' Flow IAT Std', 'Bwd IAT Total', 'Fwd PSH Flags', ' SYN Flag Count', ' Fwd Packet Length Mean', ' Avg Fwd Segment Size', ' Bwd IAT Max', ' Fwd Packet Length Std', ' Fwd IAT Mean', ' Flow IAT Mean', ' Fwd Packet Length Min', ' Init_Win_bytes_backward', ' Bwd IAT Std', 'Flow Bytes/s', 'FIN Flag Count', ' Fwd IAT Min', ' Bwd IAT Min', ' Subflow Bwd Bytes', ' Fwd Header Length', ' Fwd Header Length.1', ' Active Min', ' act_data_pkt_fwd', 'Active Mean', 'Subflow Fwd Packets', ' Active Max', ' Bwd Header Length', ' Subflow Bwd Packets', 'Fwd Packets/s', ' RST Flag Count', ' ECE Flag Count', ' Flow IAT Min', ' Active Std', ' Bwd Packets/s', ' Bwd IAT Mean', ' Subflow Fwd Bytes', ' Min Packet Length', ' Bwd Packet Length Min']\n","\n","#features_sorted_biggest_difference = [' PSH Flag Count', ' ACK Flag Count', 'Bwd Packet Length Max', ' Max Packet Length', ' Packet Length Mean', ' Average Packet Size', ' Packet Length Std', ' Avg Bwd Segment Size', ' min_seg_size_forward', ' Bwd Packet Length Std', ' Bwd Packet Length Mean', ' Packet Length Variance', 'Fwd IAT Total', ' URG Flag Count', ' Down/Up Ratio', ' Fwd IAT Max', ' Flow IAT Max', 'Init_Win_bytes_forward', 'Idle Mean', ' Fwd IAT Std', ' Flow IAT Std', 'Bwd IAT Total', 'Fwd PSH Flags', ' SYN Flag Count', ' Fwd Packet Length Mean', ' Avg Fwd Segment Size', ' Bwd IAT Max', ' Fwd Packet Length Std', ' Fwd IAT Mean', ' Flow IAT Mean', ' Fwd Packet Length Min', ' Init_Win_bytes_backward', ' Bwd IAT Std', 'Flow Bytes/s', 'FIN Flag Count', ' Fwd IAT Min', ' Bwd IAT Min', ' Subflow Bwd Bytes', ' Fwd Header Length', ' Fwd Header Length.1', ' Active Min', ' act_data_pkt_fwd', 'Active Mean', 'Subflow Fwd Packets', ' Active Max', ' Bwd Header Length', ' Subflow Bwd Packets', 'Fwd Packets/s', ' RST Flag Count', ' ECE Flag Count', ' Flow IAT Min', ' Active Std', ' Bwd Packets/s', ' Bwd IAT Mean', ' Subflow Fwd Bytes', ' Min Packet Length', ' Bwd Packet Length Min']\n","\n","#features_sorted_biggest_difference = [' PSH Flag Count', ' ACK Flag Count', 'Bwd Packet Length Max', ' Max Packet Length', ' Packet Length Mean', ' Average Packet Size', ' Packet Length Std', ' Avg Bwd Segment Size', ' min_seg_size_forward', ' Bwd Packet Length Std', ' Bwd Packet Length Mean', ' Packet Length Variance', 'Fwd IAT Total', ' URG Flag Count', ' Down/Up Ratio', ' Fwd IAT Max', ' Flow IAT Max', 'Init_Win_bytes_forward', 'Idle Mean', ' Fwd IAT Std', ' Flow IAT Std', 'Bwd IAT Total', 'Fwd PSH Flags', ' SYN Flag Count', ' Fwd Packet Length Mean', ' Avg Fwd Segment Size', ' Bwd IAT Max', ' Fwd Packet Length Std', ' Fwd IAT Mean', ' Flow IAT Mean', ' Fwd Packet Length Min', ' Init_Win_bytes_backward', ' Bwd IAT Std', 'FIN Flag Count', ' Fwd IAT Min', ' Bwd IAT Min', ' Subflow Bwd Bytes', ' Fwd Header Length', ' Fwd Header Length.1', ' Active Min', ' act_data_pkt_fwd', 'Active Mean', 'Subflow Fwd Packets', ' Active Max', ' Bwd Header Length', ' Subflow Bwd Packets', 'Fwd Packets/s', ' RST Flag Count', ' ECE Flag Count', ' Flow IAT Min', ' Active Std', ' Bwd Packets/s', ' Bwd IAT Mean', ' Subflow Fwd Bytes', ' Min Packet Length', ' Bwd Packet Length Min']\n","\n","\n","#Bot Features\n","#features_sorted_biggest_difference = [' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count', 'Init_Win_bytes_forward', 'Fwd IAT Total', 'Bwd IAT Total', 'Fwd PSH Flags', ' SYN Flag Count', ' Init_Win_bytes_backward', ' min_seg_size_forward', 'Fwd Packets/s', ' Bwd Packet Length Std', 'FIN Flag Count', ' Avg Fwd Segment Size', ' Fwd Packet Length Mean', ' Down/Up Ratio', ' Flow Packets/s', ' Bwd IAT Min', ' Fwd IAT Min', ' Fwd Packet Length Std', ' Bwd IAT Max', ' Fwd IAT Max', ' Flow IAT Max', ' Packet Length Variance', ' Bwd Packets/s', 'Idle Mean', ' Bwd IAT Mean', ' Fwd IAT Mean', ' Packet Length Std', ' Max Packet Length', ' Subflow Fwd Bytes', ' Flow IAT Min', ' Fwd Header Length', ' Subflow Bwd Bytes', ' RST Flag Count', ' ECE Flag Count', ' Bwd Header Length', ' act_data_pkt_fwd', ' Subflow Bwd Packets', 'Subflow Fwd Packets', ' Fwd Header Length.1', ' Flow IAT Std', 'Flow Bytes/s', ' Active Min', 'Active Mean', ' Active Std', ' Packet Length Mean', ' Active Max', ' Flow IAT Mean', ' Bwd IAT Std', ' Fwd IAT Std', ' Average Packet Size', ' Fwd Packet Length Min', 'Bwd Packet Length Max', ' Bwd Packet Length Mean', ' Avg Bwd Segment Size', ' Min Packet Length', ' Bwd Packet Length Min']\n","#features_sorted_biggest_difference = [' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count', 'Init_Win_bytes_forward', 'Fwd IAT Total', 'Bwd IAT Total', 'Fwd PSH Flags', ' SYN Flag Count', ' Init_Win_bytes_backward', ' min_seg_size_forward', 'Fwd Packets/s', ' Bwd Packet Length Std', 'FIN Flag Count', ' Avg Fwd Segment Size', ' Fwd Packet Length Mean', ' Down/Up Ratio', ' Bwd IAT Min', ' Fwd IAT Min', ' Fwd Packet Length Std', ' Bwd IAT Max', ' Fwd IAT Max', ' Flow IAT Max', ' Packet Length Variance', ' Bwd Packets/s', 'Idle Mean', ' Bwd IAT Mean', ' Fwd IAT Mean', ' Packet Length Std', ' Max Packet Length', ' Subflow Fwd Bytes', ' Flow IAT Min', ' Fwd Header Length', ' Subflow Bwd Bytes', ' RST Flag Count', ' ECE Flag Count', ' Bwd Header Length', ' act_data_pkt_fwd', ' Subflow Bwd Packets', 'Subflow Fwd Packets', ' Fwd Header Length.1', ' Flow IAT Std', ' Active Min', 'Active Mean', ' Active Std', ' Packet Length Mean', ' Active Max', ' Flow IAT Mean', ' Bwd IAT Std', ' Fwd IAT Std', ' Average Packet Size', ' Fwd Packet Length Min', 'Bwd Packet Length Max', ' Bwd Packet Length Mean', ' Avg Bwd Segment Size', ' Min Packet Length', ' Bwd Packet Length Min']\n","\n","\n","#Infiltration Features\n","\n","#features_sorted_biggest_difference = [' Avg Bwd Segment Size', 'FIN Flag Count', ' Subflow Bwd Bytes', ' Bwd Packet Length Mean', 'Bwd Packet Length Max', ' Init_Win_bytes_backward', ' Flow Packets/s', 'Flow Bytes/s', ' Bwd IAT Min', 'Fwd Packets/s', ' Flow IAT Min', ' Bwd Packet Length Std', ' Fwd IAT Min', ' Bwd Packets/s', ' Active Std', 'Init_Win_bytes_forward', ' Fwd IAT Mean', ' Flow IAT Mean', ' Packet Length Variance', ' Active Min', ' URG Flag Count', ' Average Packet Size', ' Bwd IAT Mean', 'Active Mean', ' Subflow Fwd Bytes', ' Packet Length Mean', 'Subflow Fwd Packets', ' Active Max', ' Subflow Bwd Packets', ' Fwd Header Length', ' Fwd Header Length.1', ' Bwd Header Length', ' act_data_pkt_fwd', ' Flow IAT Std', ' Bwd Packet Length Min', ' Fwd Packet Length Mean', ' Idle Std', ' Min Packet Length', ' Packet Length Std', ' Avg Fwd Segment Size', ' Max Packet Length', ' Fwd Packet Length Std', ' Fwd IAT Std', 'Idle Mean', ' Fwd Packet Length Min', ' PSH Flag Count', ' Bwd IAT Std', ' Down/Up Ratio', ' Idle Max', ' Bwd IAT Max', ' min_seg_size_forward', ' Fwd IAT Max', ' Flow IAT Max', 'Fwd PSH Flags', ' SYN Flag Count', 'Fwd IAT Total', 'Bwd IAT Total', ' ACK Flag Count']\n","features_sorted_biggest_difference = [' Avg Bwd Segment Size', 'FIN Flag Count', ' Subflow Bwd Bytes', ' Bwd Packet Length Mean', 'Bwd Packet Length Max', ' Init_Win_bytes_backward', ' Bwd IAT Min', 'Fwd Packets/s', ' Flow IAT Min', ' Bwd Packet Length Std', ' Fwd IAT Min', ' Bwd Packets/s', ' Active Std', 'Init_Win_bytes_forward', ' Fwd IAT Mean', ' Flow IAT Mean', ' Packet Length Variance', ' Active Min', ' URG Flag Count', ' Average Packet Size', ' Bwd IAT Mean', 'Active Mean', ' Subflow Fwd Bytes', ' Packet Length Mean', 'Subflow Fwd Packets', ' Active Max', ' Subflow Bwd Packets', ' Fwd Header Length', ' Fwd Header Length.1', ' Bwd Header Length', ' act_data_pkt_fwd', ' Flow IAT Std', ' Bwd Packet Length Min', ' Fwd Packet Length Mean', ' Idle Std', ' Min Packet Length', ' Packet Length Std', ' Avg Fwd Segment Size', ' Max Packet Length', ' Fwd Packet Length Std', ' Fwd IAT Std', 'Idle Mean', ' Fwd Packet Length Min', ' PSH Flag Count', ' Bwd IAT Std', ' Down/Up Ratio', ' Idle Max', ' Bwd IAT Max', ' min_seg_size_forward', ' Fwd IAT Max', ' Flow IAT Max', 'Fwd PSH Flags', ' SYN Flag Count', 'Fwd IAT Total', 'Bwd IAT Total', ' ACK Flag Count']\n","\n","\n","num_features = 76\n","\n","for feature_to_drop in features_sorted_biggest_difference:\n","  print(\"Dropping {}\".format(feature_to_drop))\n","  dataset = dataset.drop(columns=feature_to_drop)\n","  X = dataset\n","  num_features = num_features -1\n","\n","  # Performing scale data\n","  scaler = MinMaxScaler().fit(X)\n","  X_scaled = np.array(scaler.transform(X))\n","\n","  \n","  #X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_class, test_size = 0.7, shuffle=True, random_state = 42, stratify=Y_class)\n","\n","  kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","  cvscores = []\n","  fgsmcvscores = []\n","  for train, test in kfold.split(X_scaled, Y_class):\n","    # create model\n","\n","    \n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Dense(128, activation='relu', input_shape=[X_scaled[train].shape[1]]),\n","        tf.keras.layers.Dense(64, activation='relu'),\n","        tf.keras.layers.Dense(len(np.unique(Y_class))),\n","        tf.keras.layers.Activation(tf.nn.softmax)\n","    ])\n","\n","\n","\n","\n","\n","\n","    model.compile(optimizer='adam',\n","                  #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","                  loss= 'sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","  \n","    model.fit(X_scaled[train], Y_class[train], epochs=10)\n","  \n","    #test_loss, test_acc = model.evaluate(X_test, Y_test)\n","    scores = model.evaluate(X_scaled[test], Y_class[test])\n","    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","    cvscores.append(scores[1] * 100)\n","    #print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n","  \n","    print(\"======\\n\")\n","    print('Number of features\\t  Test accuracy:')\n","    #print(\"{}\\t{}\".format(num_features, test_acc))\n","    #features.append(num_features+1)\n","    #accuracys.append(test_acc)\n","    #print(\"{}\\t{}\".format(features,accuracys))\n","\n","    #The attack requires the model to ouput the logits\n","    logits_model = tf.keras.Model(model.input,model.layers[-1].output)\n","\n","    # Batch run on all test data\n","\n","    CLASS_TO_CHANGE = 1 # 1 will make all true cases appear as false\n","\n","    X_adv = np.zeros(X_scaled[test].shape)\n","\n","    print (X_scaled[test].shape)\n","\n","\n","    for i in range(X_scaled[test].shape[0]):\n","      current_class = Y_class[test][i]\n","      #print(\"Class:\", current_class)\n","      if current_class == CLASS_TO_CHANGE:\n","          example_vals = X_scaled[test][i, :]\n","          example_labels = Y_class[test][i]\n","          example_vals = tf.convert_to_tensor(example_vals.reshape((1, num_features+1)))\n","          example_labels = np.reshape(example_labels, (1,)).astype('int64')\n","          epsilon = 0.15\n","          adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, targeted=False)\n","          adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n","    \n","          X_adv[i,:] = adv_example_untargeted_label\n","          #X_test[i,:] = adv_example_untargeted_label\n","          #print (example_labels, \"--->\", np.argmax(adv_example_untargeted_label_pred))\n","          #print(X_test[i,:])\n","          #outputfile= pd.DataFrame(X_test[i,:])\n","          #outputfile.to_csv('mount/My Drive/Colab Notebooks/network_data/adversarial.csv')\n","\n","    print(\"This is where the Adversarial Example is\")\n","    print(X_adv)\n","    for i in range(X_adv.shape[0]):\n","        #print(X_test[i])\n","        #print(\".\")\n","        #print(example_vals) \n","        pass\n","\n","    #outputfile = pd.DataFrame(X_test)\n","    #outputfile.to_csv('mount/My Drive/Colab Notebooks/network_data/adversarial.csv')\n","    #sys.exit()\n","\n","    #find overall difference\n","    error = (X_scaled[test] - X_adv)\n","    #print (error)\n","    #find MeanSquaredError\n","    mse = tf.reduce_mean(tf.square(error, name=\"mse\"))\n","    mseerrors.append(mse)\n","\n","    mean_mses.append(np.mean(mseerrors))\n","    std_mses.append(np.std(mseerrors))\n","  \n","\n","\n","    fgsmscores = model.evaluate(X_adv, Y_class[test])\n","    print(\"%s: %.2f%%\" % (model.metrics_names[1], fgsmscores[1]*100))\n","    fgsmcvscores.append(fgsmscores[1] * 100)\n","    #print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n","    #test_loss, test_acc = model.evaluate(X_test, Y_test)\n","    #print('FGSM accuracy:', test_acc)\n","    #test_accuracys.append(test_acc)\n","    #print(\"{}\\n{}\\n{}\".format(features,accuracys,test_accuracys))\n","\n","    from sklearn.metrics import classification_report\n","\n","    y_pred = model.predict(X_adv, batch_size=64, verbose=1)\n","    y_pred_bool = np.argmax(y_pred, axis=1)\n","\n","    print(classification_report(Y_class[test], y_pred_bool))\n","\n","  features.append(num_features)\n","  mean_accuracy.append(np.mean(cvscores))\n","  std_accuracy.append(np.std(cvscores))\n","\n","  mean_fgsm_accuracy.append(np.mean(fgsmcvscores))\n","  std_fgsm_accuracy.append(np.std(fgsmcvscores))\n","  best_case_fgsm.append(np.mean(fgsmcvscores) + np.std(fgsmcvscores))\n","  worst_case_fgsm.append(np.mean(fgsmcvscores) - np.std(fgsmcvscores))\n","\n","\n","  print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n","  print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(fgsmcvscores), np.std(fgsmcvscores)))\n","    \n","  print(\"Results_Table\") \n","\n","  results_table = np.column_stack([features, mean_accuracy, std_accuracy, mean_fgsm_accuracy, std_fgsm_accuracy, best_case_fgsm, worst_case_fgsm])\n","\n","  print(results_table)\n","  np.savetxt(\"mount/My Drive/Colab Notebooks/CICIDS2017/results_table.csv\", results_table, delimiter=\",\")\n","  \n","  #plt.plot(features, mean_accuracy, linestyle='solid', c='b', label='Accuracy')\n","  plt.errorbar(features, mean_accuracy, yerr=std_accuracy, linestyle='solid', c='b', label='Accuracy')\n","  #plt.plot(features, mean_fgsm_accuracy, linestyle='solid', c='r', label='Accuracy under attack')\n","  plt.errorbar(features, mean_fgsm_accuracy, yerr=std_fgsm_accuracy, xlolims=True, label='FGSM')\n","  plt.xlabel('Features')\n","  plt.ylabel('Accuracy')\n","  plt.title('Features by Accuracy')\n","  plt.legend(loc='best')\n","  plt.show()\n","\n","  #Fudge the MSEs before printing \n","  #Take only every fifth \n","\n","  mse_fifth = []\n","\n","  for i in range(0,len(mean_mses),5):\n","    mse_fifth.append(mean_mses[i])\n","  \n","\n","  mse_for_plot = []\n","\n","  for i in range(0, len(mse_fifth)):\n","    mse_for_plot.append(mse_fifth[i]/features[i])\n","    \n","\n","\n","  plt.plot(features, mse_for_plot, linestyle='solid', c='b', label='MSE')\n","  plt.legend(loc='best')\n","  plt.xlabel('Features')\n","  plt.ylabel('MSE')\n","  plt.title('Features by Mean Squared Error')\n","  plt.show()\n","\n","\n","plt.plot(features, mean_accuracy, linestyle='solid', c='b', label='Accuracy')\n","plt.plot(features, mean_fgsm_accuracy, linestyle='solid', c='r', label='FGSM')\n","\n","plt.xlabel('Features')\n","#xticks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n","#plt.xticks(xticks,xticks)\n","plt.ylabel('Accuracy')\n","plt.title('Features by Accuracy')\n","plt.show()\n","\n","\n","#plt.scatter(mserrors[1], mserrors[1])\n","\n","#plt.scatter(X[:9999, 0], X[:9999, 1], color='blue', alpha=0.4, label='Original Data')\n","\n","\n","\n","#plt.scatter(Xadv[:9999, 0], Xadv[:9999, 1], color='green', alpha=0.4, label='Adversarial Examples, Epsilon = 0.2')\n","#plt.scatter(Xadv2[:9999, 0], Xadv2[:9999, 1], color='purple', alpha=0.4, label='Adversarial Examples, Epsilon = 0.5')\n","#plt.scatter(X[10000:, 0], X[10000:, 1], color='red', alpha=0.4, label='Original Data')\n","#plt.scatter(Xadv[10000:, 0], Xadv[10000:, 1], color='orange', alpha=0.4, label='Adversarial Examples, Epsilon = 0.2')\n","#plt.scatter(Xadv2[10000:, 0], Xadv2[10000:, 1], color='yellow', alpha=0.4, label='Adversarial Examples, Epsilon = 0.5')\n","plt.legend(loc='best')\n","plt.show()\n","\n","\n","plt.plot(features, mseerrors, linestyle='solid', c='b', label='MSE')\n","plt.legend(loc='best')\n","plt.xlabel('Features')\n","plt.ylabel('MSE')\n","plt.title('Features by Mean Squared Error')\n","\n","plt.show()"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"G3WJM6L5EmLC","executionInfo":{"status":"aborted","timestamp":1609758489794,"user_tz":0,"elapsed":347123,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["plt.plot(features, mean_accuracy, linestyle='solid', c='b', label='Accuracy')\n","plt.plot(features, mean_fgsm_accuracy, linestyle='solid', c='r', label='Accuracy under attack')\n","plt.errorbar(features, mean_fgsm_accuracy, yerr=std_fgsm_accuracy, xlolims=True, label='xlolims=True')\n","plt.xlabel('Features')\n","plt.ylabel('Accuracy')\n","plt.title('Features by Accuracy')\n","plt.legend(loc='best')\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s5q1HCEEWSyc","executionInfo":{"status":"aborted","timestamp":1609758489797,"user_tz":0,"elapsed":347122,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["#results_table = np.column_stack([features, mean_accuracy, std_accuracy, mean_fgsm_accuracy, std_fgsm_accuracy, best_case_fgsm, worst_case_fgsm])\n","\n","print(results_table)\n","\n","#np.savetxt(\"mount/My Drive/Colab Notebooks/CICIDS2017/results_table.csv\", results_table, delimiter=\",\")\n","\n","plt.scatter(features, mean_accuracy, linestyle='solid', c='b', label='Accuracy')\n","plt.scatter(features, mean_fgsm_accuracy, linestyle='solid', c='r', label='Accuracy under attack')\n","plt.xlabel('Features')\n","#xticks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n","#plt.xticks(xticks,xticks)\n","plt.ylabel('Accuracy')\n","plt.title('Features by Accuracy')\n","plt.legend(loc='best')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QnTtvHQb8Ms6","executionInfo":{"status":"aborted","timestamp":1609758489798,"user_tz":0,"elapsed":347121,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["# Import the attack\n","from cleverhans.future.tf2.attacks import fast_gradient_method\n","\n","#The attack requires the model to ouput the logits\n","logits_model = tf.keras.Model(model.input,model.layers[-1].output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0IrRrwp8Ms_","executionInfo":{"status":"aborted","timestamp":1609758489798,"user_tz":0,"elapsed":347119,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["# Get a random test case\n","ra = np.random.randint(X_test.shape[0])\n","print (\"Index:\",ra)\n","example_vals = X_test[ra, :]\n","example_labels = Y_test[ra]\n","#example_labels = Y_attack[ra]\n","\n","example_vals = tf.convert_to_tensor(example_vals.reshape((1, 77)))\n","example_labels = np.reshape(example_labels, (1,)).astype('int64')\n","\n","print (\"Values:\",example_vals)\n","print (\"Label:\", example_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xnjFgrdP8MtD","executionInfo":{"status":"aborted","timestamp":1609758489799,"user_tz":0,"elapsed":347117,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["# Non-Targeted Attack\n","\n","epsilon = 0.1\n","\n","adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, targeted=False)\n","adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n","\n","print (\"Original Label:\" , example_labels)\n","print (\"FGSM Label:\", np.argmax(adv_example_untargeted_label_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ze9tzgi88MtM","executionInfo":{"status":"aborted","timestamp":1609758489800,"user_tz":0,"elapsed":347116,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["# Batch run on all test data\n","\n","CLASS_TO_CHANGE = 1 # 1 will make all true cases appear as false\n","\n","X_adv = np.zeros(X_test.shape)\n","\n","print (X_test.shape)\n","for i in range(X_test.shape[0]):\n","    current_class = Y_test[i]\n","    #print(\"Class:\", current_class)\n","    if current_class == CLASS_TO_CHANGE:\n","        example_vals = X_test[i, :]\n","        example_labels = Y_test[i]\n","        example_vals = tf.convert_to_tensor(example_vals.reshape((1, 77)))\n","        example_labels = np.reshape(example_labels, (1,)).astype('int64')\n","        epsilon = 0.1\n","        adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, targeted=False)\n","        adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n","    \n","        X_adv[i,:] = adv_example_untargeted_label\n","        X_test[i,:] = adv_example_untargeted_label\n","        #print (example_labels, \"--->\", np.argmax(adv_example_untargeted_label_pred))\n","\n","test_loss, test_acc = model.evaluate(X_test, Y_test)\n","print('Test accuracy:', test_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A8Xs285k8MtR"},"source":["## Multi-class Classification"]},{"cell_type":"code","metadata":{"id":"I2X6qnk98MtS","executionInfo":{"status":"aborted","timestamp":1609758489800,"user_tz":0,"elapsed":347113,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_attack, test_size = 0.7, random_state = 42, stratify=Y_class)\n","print (\"X_Train:\", X_train.shape)\n","print (\"X_Test:\", X_test.shape)\n","print (\"Y_Train:\", Y_train.shape)\n","print (\"Y_Test:\", Y_test.shape)\n","\n","print(np.unique(Y_attack), len(np.unique(Y_attack)), Y_attack)\n","\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(128, activation='relu', input_shape=[X_train.shape[1]]),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(len(np.unique(Y_attack))),\n","    tf.keras.layers.Activation(tf.nn.softmax)\n","])\n","\n","model.compile(optimizer='adam',\n","              loss= 'sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(X_train, Y_train, epochs=10, validation_split=0.2)\n","test_loss, test_acc = model.evaluate(X_test, Y_test)\n","print('Test accuracy:', test_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dd7PYfsP8MtW","executionInfo":{"status":"aborted","timestamp":1609758489801,"user_tz":0,"elapsed":347111,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["# Import the attack\n","from cleverhans.future.tf2.attacks import fast_gradient_method\n","\n","#The attack requires the model to ouput the logits\n","logits_model = tf.keras.Model(model.input,model.layers[-1].output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZKONDuim8Mta","executionInfo":{"status":"aborted","timestamp":1609758489801,"user_tz":0,"elapsed":347109,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["# Get a random test case\n","ra = np.random.randint(X_test.shape[0])\n","print (\"Index:\",ra)\n","example_vals = X_test[ra, :]\n","#example_labels = Y_test[ra]\n","example_labels = Y_attack[ra]\n","\n","example_vals = tf.convert_to_tensor(example_vals.reshape((1, 77)))\n","example_labels = np.reshape(example_labels, (1,)).astype('int64')\n","\n","print (\"Values:\",example_vals)\n","print (\"Label:\", example_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iPRagwZl8Mtc","executionInfo":{"status":"aborted","timestamp":1609758489802,"user_tz":0,"elapsed":347108,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["# Non-Targeted Attack\n","\n","epsilon = 0.1\n","\n","adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, targeted=False)\n","adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n","\n","print (\"Original Label:\" , example_labels)\n","print (\"FGSM Label:\", np.argmax(adv_example_untargeted_label_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7NsnwHJo8Mtx","executionInfo":{"status":"aborted","timestamp":1609758489803,"user_tz":0,"elapsed":347106,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["text_labels = []\n","text_labels.append(\"Benign\")\n","text_labels.append(\"Bot\")\n","text_labels.append(\"DDoS GoldenEye\")\n","text_labels.append(\"DDoS Hulk\")\n","text_labels.append(\"DDoS Slowhttptest\")\n","text_labels.append(\"slowloris\")\n","text_labels.append(\"FTP-Patator\")\n","text_labels.append(\"Heartbleed\")\n","text_labels.append(\"Infiltration\")\n","#text_labels.append(\"Label\")\n","text_labels.append(\"SSH-Patator\")\n","text_labels.append(\"Web Attack - Brute Force\")\n","text_labels.append(\"Web Attack - Sql Injection\")\n","text_labels.append(\"Web Attack - XSS\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nz64szxP8Mth","executionInfo":{"status":"aborted","timestamp":1609758489803,"user_tz":0,"elapsed":347104,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["# Batch run on all test data\n","mserrors = []\n","graph_labels = []\n","\n","for all_classes in range(15):\n","  CLASS_TO_CHANGE = all_classes # 0 will change all that have 0 to some other untargeted class\n","  X_adv = np.zeros(X_test.shape)\n","\n","\n","  \n","\n","  print (X_test.shape)\n","  for i in range(X_test.shape[0]):\n","      current_class = Y_test[i]\n","      #print(\"Class:\", current_class)\n","      if current_class == CLASS_TO_CHANGE:\n","          example_vals = X_test[i, :]\n","          example_labels = Y_test[i]\n","          example_vals = tf.convert_to_tensor(example_vals.reshape((1, 77)))\n","          example_labels = np.reshape(example_labels, (1,)).astype('int64')\n","          epsilon = 0.1\n","          adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, targeted=False)\n","          adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n","\n","          X_adv[i,:] = adv_example_untargeted_label\n","          X_test[i,:] = adv_example_untargeted_label\n","          #print (example_labels, \"--->\", np.argmax(adv_example_untargeted_label_pred))\n","          \n","          #find overall difference\n","          error = (X_test - X_adv)\n","          #print (error)\n","          #find MeanSquaredError\n","          mse = tf.reduce_mean(tf.square(error, name=\"mse\"))\n","          mserrors.append(mse)\n","          graph_labels.append(current_class)\n","\n","          \n","          #print(mse)\n","\n","          # find difference in each feature\n","\n","          #print(example_vals)\n","          for feature in range(77): \n","            if (X_test[i][feature] != X_adv[i][feature]):\n","              print(\"Example: {} Feature: {} + {} {}\".format(i, feature, X_test[i][feature], X_adv[i][feature]))\n","\n","            pass\n","\n","        \n","\n","  test_loss, test_acc = model.evaluate(X_test, Y_test)\n","  print('Test accuracy:', test_acc)\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TOso9J2EE9bq","executionInfo":{"status":"aborted","timestamp":1609758489804,"user_tz":0,"elapsed":347103,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["print(np.array(graph_labels).shape)\n","print(np.array(mserrors).shape)\n","\n","xplot = np.array(graph_labels)\n","yplot = np.array(mserrors) \n","\n","plt.scatter(xplot, yplot)\n","plt.xlabel('Class')\n","xticks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n","plt.xticks(xticks,xticks)\n","plt.ylabel('Mean Squared Error')\n","plt.title('Size of difference required to change original data to be recognised as another class')\n","#plt.scatter(mserrors[1], mserrors[1])\n","\n","#plt.scatter(X[:9999, 0], X[:9999, 1], color='blue', alpha=0.4, label='Original Data')\n","\n","\n","\n","#plt.scatter(Xadv[:9999, 0], Xadv[:9999, 1], color='green', alpha=0.4, label='Adversarial Examples, Epsilon = 0.2')\n","#plt.scatter(Xadv2[:9999, 0], Xadv2[:9999, 1], color='purple', alpha=0.4, label='Adversarial Examples, Epsilon = 0.5')\n","#plt.scatter(X[10000:, 0], X[10000:, 1], color='red', alpha=0.4, label='Original Data')\n","#plt.scatter(Xadv[10000:, 0], Xadv[10000:, 1], color='orange', alpha=0.4, label='Adversarial Examples, Epsilon = 0.2')\n","#plt.scatter(Xadv2[10000:, 0], Xadv2[10000:, 1], color='yellow', alpha=0.4, label='Adversarial Examples, Epsilon = 0.5')\n","plt.legend(loc='best')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OH65_t8q8Mts"},"source":["### Targeted Attack on the Multi-Class Classification"]},{"cell_type":"code","metadata":{"id":"QmkYdF1D8Mtt","executionInfo":{"status":"aborted","timestamp":1609758489804,"user_tz":0,"elapsed":347101,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["epsilon = 0.1\n","# The target value may have to be changed to work, some images are more easily missclassified as different labels\n","target = 5\n","target_label = np.reshape(target, (1,)).astype('int64') # Give target label proper size and dtype to feed through\n","adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, y=target_label, targeted=True)\n","adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n","\n","print (\"Original Label:\" , example_labels)\n","print (\"FGSM Label:\", np.argmax(adv_example_untargeted_label_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wm-0RaMW8Mtw"},"source":["## Further Actions\n","\n","This notebook shows how to perform FGSM against the CICIDS2017 dataset. Some points to consider for further work:\n","\n","* This mostly replicates what was in the IDS.py example. The added batch test at the end of each of the two methods will compromise a given class, re-insert the new adversarial features, and then re-test the classifier performance with these values. What is the perturbation in the adversarial cases? (Hint: Look at X_adv, and think how it should be used with X_test).\n","* How may you study the decision boundaries of all features? (If we had 2 features then a scatter plot would work. If we reduce dimensionality using PCA then scatter plot works, but we lose original data. Parallel Co-ordinates could help here.) What is the expected range of values for a given class.\n","* What value of epsilon is required to shift between classes? (For multi-class) Which classes can be most easily manipulated (this is essentially the same as asking which classes appear close in feature space).\n","* Most examples of adversarial learning focus on images because of the weakness in human vision and the conversion of pixel intensity to numerical values for computation. In cases like this where the data is inherently numerical, how does an attacker 'disguise' their attack, and how does a 'defender' notice this (i.e., what correlations exist between features, and do adversarial examples contradict the expected correlations - is this the way to spot such cases?"]},{"cell_type":"code","metadata":{"id":"iNZUJYVM8Mt0","executionInfo":{"status":"aborted","timestamp":1609758489805,"user_tz":0,"elapsed":347100,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dOwjuPgv7f5b","executionInfo":{"status":"aborted","timestamp":1609758489805,"user_tz":0,"elapsed":347098,"user":{"displayName":"Andrew McCarthy","photoUrl":"","userId":"03997052940471236928"}}},"source":["  #print(mserrors)\n","\n","  #print(min(mserrors))\n","  print(\"Minimum MSE: {}\".format(min(mserrors)))\n","  print(\"Maximum MSE: {}\".format(max(mserrors)))\n","  print(\"Mean MSE: {}\".format((sum(mserrors)/len(mserrors))))\n","\n","  temp = min(mserrors) \n","  res = [] \n","  for idx in range(0, len(mserrors)): \n","      if temp == mserrors[idx]: \n","          res.append(idx) \n","      \n","  # Printing result \n","  print(\"The Positions of minimum element : \" + str(res)) \n","  minindex = res\n","\n","\n","  temp = max(mserrors) \n","  res = [] \n","  for idx in range(0, len(mserrors)): \n","      if temp == mserrors[idx]: \n","          res.append(idx) \n","      \n","  # Printing result \n","  print(\"The Positions of maximum element : \" + str(res)) \n","  maxindex = res\n","\n","\n","  #show the minimum perturbations\n","  print(\"Minimum Perturbation-------------\")\n","  print(X_test[minindex])\n","  orig_label = int(Y_test[minindex])\n","  print(\"Original Label: {}\".format(text_labels[orig_label]))\n","\n","\n","  #show the maximum perturbations\n","  print(\"Maximum Perturbation-------------\")\n","  print(X_test[maxindex])\n","  orig_label = int(Y_test[maxindex])\n","  print(\"Original Label: {}\".format(text_labels[orig_label]))\n"],"execution_count":null,"outputs":[]}]}