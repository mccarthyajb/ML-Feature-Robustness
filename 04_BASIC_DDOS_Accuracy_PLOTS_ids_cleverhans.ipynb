{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "04-BASIC DDOS Accuracy PLOTS ids_cleverhans.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8eqx1sY8Msg"
      },
      "source": [
        "# Adversarial Learning against Intrusion Detection Systems\n",
        "\n",
        "In this notebook, we examine the feasibility of adversarial learning in the context of Intrusion Detection. We use the CICIDS2017 dataset and create a learning model to perform binary classification against this. We then study how this holds against FGSM attacks, and the amount of perturbation required to create a false result. We then explore how different parameter counts hold against this attack vector, to assess the robustness of the feature sets being used for learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdNzTR-h8Msi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3da8a51-a169-4e40-816a-d0cd0dc0f76f"
      },
      "source": [
        "!pip install -q tensorflow==2.0.0b1\n",
        "# Install bleeding edge version of cleverhans\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "\n",
        "import cleverhans\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nTensorflow Version: \" + tf.__version__)\n",
        "print(\"Cleverhans Version: \" + cleverhans.__version__)\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 87.9MB 64kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 37.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 44.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 4.4MB/s \n",
            "\u001b[?25hCollecting cleverhans\n",
            "  Cloning https://github.com/tensorflow/cleverhans.git to /tmp/pip-install-lst7v4mj/cleverhans\n",
            "  Running command git clone -q https://github.com/tensorflow/cleverhans.git /tmp/pip-install-lst7v4mj/cleverhans\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 4.3MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5b/88879fb861ab79aef45c7e199cae3ef7af487b5603dcb363517a50602dd7/pycodestyle-2.6.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.2)\n",
            "Collecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans) (0.12.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.1.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=262572 sha256=10b1303988167bd25424d7c1c7a635896b6c8276b00f49ebd6c2c5380076fb3a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9m3suiee/wheels/6e/59/ec/723a6f654aaf62c8c40f0f0850fdf71a4948598697f56c3bfa\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tensorflow Version: 2.0.0-beta1\n",
            "Cleverhans Version: 3.0.1-80ec37b63b5b9bd57c94c6d6f2607068\n",
            "GPU Available:  False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNa-TEG98Msq"
      },
      "source": [
        "## Load in the Dataset\n",
        "\n",
        "We will load in the CICIDS 2017 - this can be used either based on the binary class or the multi-class label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iWwlWjj8Msr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f4e0a9-208a-416c-e6ed-232375b77565"
      },
      "source": [
        "import pandas as pd\n",
        "import sys as sys\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('./mount')\n",
        "print(\"Drive Mounted\")\n",
        "\n",
        "dataset = pd.read_csv('mount/My Drive/Colab Notebooks/CICIDS2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
        "#dataset = pd.read_csv('mount/My Drive/Colab Notebooks/network_data/CICIDS2017_dataset.csv')\n",
        "#dataset = pd.read_csv('mount/My Drive/Colab Notebooks/network_data/CICIDS2017_FeatureImportancesWithoutRankings.csv')\n",
        "print (\"Dataset Shape\", dataset.shape)\n",
        "print(dataset)\n",
        "# Creating X and Y from the dataset\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(dataset[' Label'])\n",
        "Y_attack = le.transform(dataset[' Label']) # multi-class \n",
        "\n",
        "#print(list(le.classes_))\n",
        "#print(np.unique(Y_attack))\n",
        "\n",
        "print(\"Dropping Flow Bytes and Flow Packets\")\n",
        "dataset = dataset.drop(columns='Flow Bytes/s')\n",
        "dataset = dataset.drop(columns=' Flow Packets/s')\n",
        "\n",
        "# Transform Objects to Digits\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "for column_name in dataset.columns:\n",
        "        if dataset[column_name].dtype == object:\n",
        "            print(dataset[column_name])\n",
        "            dataset[column_name] = le.fit_transform(dataset[column_name])\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "\n",
        "Y_class = dataset.iloc[:,-1].values # binary\n",
        "X = dataset.iloc[:,0:80].values\n",
        "\n",
        "\n",
        "\n",
        "X = X.astype(float)\n",
        "\n",
        "# Performing scale data\n",
        "scaler = MinMaxScaler().fit(X)\n",
        "X_scaled = np.array(scaler.transform(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./mount\n",
            "Drive Mounted\n",
            "Dataset Shape (225745, 79)\n",
            "         Destination Port   Flow Duration  ...   Idle Min   Label\n",
            "0                   54865               3  ...          0  BENIGN\n",
            "1                   55054             109  ...          0  BENIGN\n",
            "2                   55055              52  ...          0  BENIGN\n",
            "3                   46236              34  ...          0  BENIGN\n",
            "4                   54863               3  ...          0  BENIGN\n",
            "...                   ...             ...  ...        ...     ...\n",
            "225740              61374              61  ...          0  BENIGN\n",
            "225741              61378              72  ...          0  BENIGN\n",
            "225742              61375              75  ...          0  BENIGN\n",
            "225743              61323              48  ...          0  BENIGN\n",
            "225744              61326              68  ...          0  BENIGN\n",
            "\n",
            "[225745 rows x 79 columns]\n",
            "Dropping Flow Bytes and Flow Packets\n",
            "0         BENIGN\n",
            "1         BENIGN\n",
            "2         BENIGN\n",
            "3         BENIGN\n",
            "4         BENIGN\n",
            "           ...  \n",
            "225740    BENIGN\n",
            "225741    BENIGN\n",
            "225742    BENIGN\n",
            "225743    BENIGN\n",
            "225744    BENIGN\n",
            "Name:  Label, Length: 225745, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0cw1_kX0i58"
      },
      "source": [
        "## kfold\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59gBhj150ulj"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=True,random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLKe1V2R8Msy"
      },
      "source": [
        "## Binary Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n21pZLxJ8Msz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bfcc020b-2395-4b38-d42c-335172475163"
      },
      "source": [
        "# Import the attack\n",
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "features = []\n",
        "accuracys = []\n",
        "mseerrors = []\n",
        "minmseerrors = []\n",
        "test_accuracys = []\n",
        "\n",
        "for num_features in [76]:\n",
        "  #X = dataset.iloc[:,0:num_features+1].values\n",
        "  #X = X.astype(int)\n",
        "\n",
        "  # Performing scale data\n",
        "  scaler = MinMaxScaler().fit(X)\n",
        "  X_scaled = np.array(scaler.transform(X))\n",
        "\n",
        "  \n",
        "  #X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_class, test_size = 0.7, shuffle=True, random_state = 42, stratify=Y_class)\n",
        "\n",
        "  kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "  cvscores = []\n",
        "  fgsmcvscores = []\n",
        "  for train, test in kfold.split(X_scaled, Y_class):\n",
        "    # create model\n",
        "\n",
        "    \n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=[X_scaled[train].shape[1]]),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(len(np.unique(Y_class))),\n",
        "        tf.keras.layers.Activation(tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  loss= 'sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "  \n",
        "    model.fit(X_scaled[train], Y_class[train], epochs=10)\n",
        "  \n",
        "    #test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "    scores = model.evaluate(X_scaled[test], Y_class[test])\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "    #print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "  \n",
        "    print(\"======\\n\")\n",
        "    print('Number of features\\t  Test accuracy:')\n",
        "    #print(\"{}\\t{}\".format(num_features, test_acc))\n",
        "    #features.append(num_features+1)\n",
        "    #accuracys.append(test_acc)\n",
        "    #print(\"{}\\t{}\".format(features,accuracys))\n",
        "\n",
        "    #The attack requires the model to ouput the logits\n",
        "    logits_model = tf.keras.Model(model.input,model.layers[-1].output)\n",
        "\n",
        "    # Batch run on all test data\n",
        "\n",
        "    CLASS_TO_CHANGE = 1 # 1 will make all true cases appear as false\n",
        "\n",
        "    X_adv = np.zeros(X_scaled[test].shape)\n",
        "\n",
        "    print (X_scaled[test].shape)\n",
        "\n",
        "\n",
        "    for i in range(X_scaled[test].shape[0]):\n",
        "      current_class = Y_class[test][i]\n",
        "      #print(\"Class:\", current_class)\n",
        "      if current_class == CLASS_TO_CHANGE:\n",
        "          example_vals = X_scaled[test][i, :]\n",
        "          example_labels = Y_class[test][i]\n",
        "          example_vals = tf.convert_to_tensor(example_vals.reshape((1, num_features+1)))\n",
        "          example_labels = np.reshape(example_labels, (1,)).astype('int64')\n",
        "          epsilon = 0.1\n",
        "          adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, targeted=False)\n",
        "          adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n",
        "    \n",
        "          X_adv[i,:] = adv_example_untargeted_label\n",
        "          #X_test[i,:] = adv_example_untargeted_label\n",
        "          #print (example_labels, \"--->\", np.argmax(adv_example_untargeted_label_pred))\n",
        "          #print(X_test[i,:])\n",
        "          #outputfile= pd.DataFrame(X_test[i,:])\n",
        "          #outputfile.to_csv('mount/My Drive/Colab Notebooks/network_data/adversarial.csv')\n",
        "\n",
        "    print(\"This is where the Adversarial Example is\")\n",
        "    print(X_adv)\n",
        "    for i in range(X_adv.shape[0]):\n",
        "        #print(X_test[i])\n",
        "        #print(\".\")\n",
        "        #print(example_vals) \n",
        "        pass\n",
        "\n",
        "    #outputfile = pd.DataFrame(X_test)\n",
        "    #outputfile.to_csv('mount/My Drive/Colab Notebooks/network_data/adversarial.csv')\n",
        "    #sys.exit()\n",
        "\n",
        "    #find overall difference\n",
        "    #error = (X_test - X_adv)\n",
        "    #print (error)\n",
        "    #find MeanSquaredError\n",
        "    #mse = tf.reduce_mean(tf.square(error, name=\"mse\"))\n",
        "    #mseerrors.append(mse)\n",
        "  \n",
        "\n",
        "\n",
        "    fgsmscores = model.evaluate(X_adv, Y_class[test])\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], fgsmscores[1]*100))\n",
        "    fgsmcvscores.append(fgsmscores[1] * 100)\n",
        "    #print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "    #test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "    #print('FGSM accuracy:', test_acc)\n",
        "    #test_accuracys.append(test_acc)\n",
        "    #print(\"{}\\n{}\\n{}\".format(features,accuracys,test_accuracys))\n",
        "\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(fgsmcvscores), np.std(fgsmcvscores)))\n",
        "    \n",
        "    \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "plt.plot(features, accuracys, linestyle='solid', c='b', label='Accuracy')\n",
        "plt.plot(features, test_accuracys, linestyle='solid', c='r', label='Accuracy under attack')\n",
        "plt.xlabel('Features')\n",
        "#xticks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
        "#plt.xticks(xticks,xticks)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Features by Accuracy')\n",
        "#plt.scatter(mserrors[1], mserrors[1])\n",
        "\n",
        "#plt.scatter(X[:9999, 0], X[:9999, 1], color='blue', alpha=0.4, label='Original Data')\n",
        "\n",
        "\n",
        "\n",
        "#plt.scatter(Xadv[:9999, 0], Xadv[:9999, 1], color='green', alpha=0.4, label='Adversarial Examples, Epsilon = 0.2')\n",
        "#plt.scatter(Xadv2[:9999, 0], Xadv2[:9999, 1], color='purple', alpha=0.4, label='Adversarial Examples, Epsilon = 0.5')\n",
        "#plt.scatter(X[10000:, 0], X[10000:, 1], color='red', alpha=0.4, label='Original Data')\n",
        "#plt.scatter(Xadv[10000:, 0], Xadv[10000:, 1], color='orange', alpha=0.4, label='Adversarial Examples, Epsilon = 0.2')\n",
        "#plt.scatter(Xadv2[10000:, 0], Xadv2[10000:, 1], color='yellow', alpha=0.4, label='Adversarial Examples, Epsilon = 0.5')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(features, mseerrors, linestyle='solid', c='b', label='MSE')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('Features by Mean Squared Error')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 180596 samples\n",
            "Epoch 1/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 0.0032 - accuracy: 0.9993\n",
            "Epoch 2/10\n",
            "180596/180596 [==============================] - 11s 58us/sample - loss: 2.8903e-07 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "180596/180596 [==============================] - 11s 63us/sample - loss: 1.2422e-07 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "180596/180596 [==============================] - 11s 63us/sample - loss: 1.1998e-07 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "180596/180596 [==============================] - 12s 65us/sample - loss: 1.1941e-07 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "180596/180596 [==============================] - 10s 57us/sample - loss: 1.1928e-07 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "180596/180596 [==============================] - 10s 56us/sample - loss: 1.1925e-07 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "180596/180596 [==============================] - 10s 57us/sample - loss: 1.1923e-07 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "180596/180596 [==============================] - 10s 57us/sample - loss: 1.1923e-07 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "180596/180596 [==============================] - 10s 57us/sample - loss: 1.1922e-07 - accuracy: 1.0000\n",
            "45149/45149 [==============================] - 1s 25us/sample - loss: 1.1922e-07 - accuracy: 1.0000\n",
            "accuracy: 100.00%\n",
            "======\n",
            "\n",
            "Number of features\t  Test accuracy:\n",
            "(45149, 77)\n",
            "WARNING:tensorflow:Entity <function compute_gradient at 0x7f39580f0d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function compute_gradient at 0x7f39580f0d90>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function compute_gradient at 0x7f39580f0d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function compute_gradient at 0x7f39580f0d90>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "This is where the Adversarial Example is\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "45149/45149 [==============================] - 1s 25us/sample - loss: 4.2210 - accuracy: 0.5442\n",
            "accuracy: 54.42%\n",
            "Train on 180596 samples\n",
            "Epoch 1/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 0.0029 - accuracy: 0.9995\n",
            "Epoch 2/10\n",
            "180596/180596 [==============================] - 11s 58us/sample - loss: 3.9617e-07 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "180596/180596 [==============================] - 10s 58us/sample - loss: 1.2852e-07 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 1.2016e-07 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 1.1948e-07 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "180596/180596 [==============================] - 10s 58us/sample - loss: 1.1930e-07 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "180596/180596 [==============================] - 11s 58us/sample - loss: 1.1925e-07 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 1.1923e-07 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "180596/180596 [==============================] - 11s 61us/sample - loss: 1.1923e-07 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "180596/180596 [==============================] - 11s 63us/sample - loss: 1.1922e-07 - accuracy: 1.0000\n",
            "45149/45149 [==============================] - 1s 27us/sample - loss: 1.1924e-07 - accuracy: 1.0000\n",
            "accuracy: 100.00%\n",
            "======\n",
            "\n",
            "Number of features\t  Test accuracy:\n",
            "(45149, 77)\n",
            "WARNING:tensorflow:Entity <function compute_gradient at 0x7f39580f0d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function compute_gradient at 0x7f39580f0d90>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function compute_gradient at 0x7f39580f0d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function compute_gradient at 0x7f39580f0d90>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "This is where the Adversarial Example is\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "45149/45149 [==============================] - 1s 24us/sample - loss: 7.3972 - accuracy: 0.4329\n",
            "accuracy: 43.29%\n",
            "Train on 180596 samples\n",
            "Epoch 1/10\n",
            "180596/180596 [==============================] - 10s 58us/sample - loss: 0.0030 - accuracy: 0.9994\n",
            "Epoch 2/10\n",
            "180596/180596 [==============================] - 10s 57us/sample - loss: 2.5541e-07 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "180596/180596 [==============================] - 10s 56us/sample - loss: 1.2285e-07 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "180596/180596 [==============================] - 10s 57us/sample - loss: 1.1976e-07 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "180596/180596 [==============================] - 10s 56us/sample - loss: 1.1936e-07 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "180596/180596 [==============================] - 10s 56us/sample - loss: 1.1927e-07 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "180596/180596 [==============================] - 10s 57us/sample - loss: 1.1925e-07 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "180596/180596 [==============================] - 10s 57us/sample - loss: 1.1923e-07 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "180596/180596 [==============================] - 10s 57us/sample - loss: 1.1922e-07 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "180596/180596 [==============================] - 10s 56us/sample - loss: 1.1922e-07 - accuracy: 1.0000\n",
            "45149/45149 [==============================] - 1s 24us/sample - loss: 1.1922e-07 - accuracy: 1.0000\n",
            "accuracy: 100.00%\n",
            "======\n",
            "\n",
            "Number of features\t  Test accuracy:\n",
            "(45149, 77)\n",
            "WARNING:tensorflow:Entity <function compute_gradient at 0x7f39580f0d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function compute_gradient at 0x7f39580f0d90>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function compute_gradient at 0x7f39580f0d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function compute_gradient at 0x7f39580f0d90>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "This is where the Adversarial Example is\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "45149/45149 [==============================] - 1s 25us/sample - loss: 4.6960 - accuracy: 0.4329\n",
            "accuracy: 43.29%\n",
            "Train on 180596 samples\n",
            "Epoch 1/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 0.0031 - accuracy: 0.9996\n",
            "Epoch 2/10\n",
            "180596/180596 [==============================] - 11s 58us/sample - loss: 3.2491e-07 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 1.2410e-07 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 1.1997e-07 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "180596/180596 [==============================] - 11s 60us/sample - loss: 1.1937e-07 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "180596/180596 [==============================] - 11s 58us/sample - loss: 1.1927e-07 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "180596/180596 [==============================] - 11s 60us/sample - loss: 1.1924e-07 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 1.1923e-07 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "180596/180596 [==============================] - 11s 58us/sample - loss: 1.1922e-07 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 1.1922e-07 - accuracy: 1.0000\n",
            "45149/45149 [==============================] - 1s 25us/sample - loss: 1.1978e-07 - accuracy: 1.0000\n",
            "accuracy: 100.00%\n",
            "======\n",
            "\n",
            "Number of features\t  Test accuracy:\n",
            "(45149, 77)\n",
            "WARNING:tensorflow:Entity <function compute_gradient at 0x7f39580f0d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function compute_gradient at 0x7f39580f0d90>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function compute_gradient at 0x7f39580f0d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function compute_gradient at 0x7f39580f0d90>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "This is where the Adversarial Example is\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "45149/45149 [==============================] - 1s 28us/sample - loss: 5.8003 - accuracy: 0.4329\n",
            "accuracy: 43.29%\n",
            "Train on 180596 samples\n",
            "Epoch 1/10\n",
            "180596/180596 [==============================] - 13s 70us/sample - loss: 0.0033 - accuracy: 0.9989\n",
            "Epoch 2/10\n",
            "180596/180596 [==============================] - 11s 62us/sample - loss: 2.7029e-07 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 1.2346e-07 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 1.1980e-07 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 1.1935e-07 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "180596/180596 [==============================] - 11s 58us/sample - loss: 1.1927e-07 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "180596/180596 [==============================] - 11s 61us/sample - loss: 1.1924e-07 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 1.1923e-07 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 1.1922e-07 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "180596/180596 [==============================] - 11s 59us/sample - loss: 1.1922e-07 - accuracy: 1.0000\n",
            "45149/45149 [==============================] - 1s 25us/sample - loss: 1.1926e-07 - accuracy: 1.0000\n",
            "accuracy: 100.00%\n",
            "======\n",
            "\n",
            "Number of features\t  Test accuracy:\n",
            "(45149, 77)\n",
            "WARNING:tensorflow:Entity <function compute_gradient at 0x7f39580f0d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function compute_gradient at 0x7f39580f0d90>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function compute_gradient at 0x7f39580f0d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function compute_gradient at 0x7f39580f0d90>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "This is where the Adversarial Example is\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "45149/45149 [==============================] - 1s 26us/sample - loss: 7.3665 - accuracy: 0.4329\n",
            "accuracy: 43.29%\n",
            "100.00% (+/- 0.00%)\n",
            "45.51% (+/- 4.45%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAb70lEQVR4nO3dfbxVZZ338c83QCE1BcQHPBL40K34hLrVsck7G/ExEu5yRuU2UTSnGU0ds7KXlajZqJOTpb2aIXUCm1DH6o7JlFAkGyv1oOiAZjxIcRANAR0VTdHf/ce6Di52+zxwnbPP5ni+79drv85a67r2Wr/r7PM6373WtR8UEZiZmW2q9zS6ADMz650cIGZmlsUBYmZmWRwgZmaWxQFiZmZZHCBmZpbFAWLvepJGSgpJ/Rtdi71D0pGSWhpdh+VzgBgAkpZJek3SK6Xb8G7Y59juqnFzIGlKCqMLqrZfkLZPaUBNH5L0K0kvSVoj6UFJh/R0Hd0t/T5frfqb/Hyj67J3+BmZlX0sIu5tdBGtJPWPiPWNrqOG3wGnA98sbZuUtvcoSe8Dfgr8HXAHsAVwBPCnBtTSLyLe6ubdHhARiztx7I3+ViQJUES83ZmDbGp/K/gMxNolaVtJN0taKWmFpK9K6pfadpc0R9JqSS9I+ndJ26W2W4ERwH+2PnOsdcmifJaSnt3fKen7kv4HOKOD4+8h6RfpmfcLkm7vYDiTJT2b9nVx2sdOktZJGlqq6SBJqyQNaGM/jwDvlbRP6r8PMDBtL49tnKT5kl5MZwj7l9oukbRE0suSnpT0f0ptZ0j6L0lfl7RW0jOSjm+jlg8ARMSMiHgrIl6LiJ9HxBNpX/3Sfl6QtFTSueXLedVniekx+H5p/T8kPZd+xw+0jjm1fU/SdyT9TNKrwEckDZf0w/T7e0bS+aX+g9J91kp6Esg+S2rjb2WupKskPQisA3aT9EFJj6T6H5H0wdI+/qx/bj19lQPEOvI9YD2wB3AgcAxwdmoT8I/AcGBvYFdgCkBEfBL4A8VZzdYRcW0njzceuBPYDvj3Do5/JfBzYDDQBNzQwb4/AuyZ9vEFSWMj4jlgLvA3pX6fBG6LiDfb2detFGchUJx93FpulHQgcAvwt8BQ4F+BmZK2TF2WUJwpbAtcDnxf0s6lXRwGPA1sD1wL3JyeJVf7HfCWpGmSjpc0uKr9U8A4it9dBTipnTHVcjfF72wH4FGKx6RsInAVsA3wK+A/gceBXYCjgAslHZv6Xgbsnm7HUvzeuqL6bwWKx+6cVM/LwF3Atygeg38G7io/Wajq//su1tP3RIRvvgEsA14BXky3/wfsSHEpZFCp36nA/W3sYwLwWNU+x5bWjwRaahx3bFqeAjxQamv3+MB0YCrQ1MHYRgIB7FXadi1wc1o+GXgwLfcDngMObWNfU4DvU5xd/QEYkH7umrZPSf2+A1xZdd+ngQ+3sd/5wPi0fAawuNT23lT/Tm3cd2+KoG2hCNuZwI6pbQ7w6VLfY9K++rfxGE0Bvt/GcbZL9902rX8PmF5qPwz4Q9V9vgj8W1peChxXajun+u+h6r4B/E/pb/JF4Nhafytp21zgitL6J4GHq/r8GjijVn/fNv3mORArmxClORBJh1L8g1xZevL7HmB5at+RYh7gCIpncO8B1naxhuWl5fe3d3zg8xRnIQ9LWgtcFxG3dHLfvwf2S8s/Af5F0ijgfwEvRcTD7RUZEX+QtBj4GrAoIpZXnSC8H5gk6TOlbVtQnK0h6XTgIopwA9ia4myj1XOlY61L+966jVqeoggdJO1FEWTXU4Tt8Brj7pR0qfAq4K+BYUDr/MD2wEtpufrxGi7pxdK2fsAv03JOLQdF23MgyzvYNrzGMX5PcXbU3j6skxwg1p7lFGcA20ftyeyvUTxL3C8i1kiaANxYaq/+qOdXKZ5NAxv+QQ2r6lO+T7vHj+Ly06fSvj4E3CvpgXb+4ewK/DYtjwCeTft5XdIdwGnAXlRdjmrHdIrLVGfWaFsOXBURV1U3SHo/8F2KSzy/joi3JM2nuCTYJRHxW0nfo7h0BrCSYtytRlTdZaPHBNiptDyR4jLRWIozlW0pniCU66x+vJ6JiD3bKK+1loVt1LKpan2UeHnbsxShVjYCuKeDfVgneQ7E2hQRKynmGK6T9D5J71Excf7h1GUbisteL0naBfhc1S6eZ+OJyd8BAyV9NE1QfwnYkjZ0dHxJfy2pKXVfS/HPoL1X0XxZUuvk95lAedJ9OsWz+BPpfIDcTnFJ6I4abd8FPi3pMBW2SuPeBtgq1boqjeNMYN9OHnMjkvaS9NnW34OkXSnOPH6TutwBnC+pKc2PXFK1i/nAKZIGSKqeI9mGIsBXU4TM1zoo52HgZUlfSBPm/STtq3deUnwH8EVJg1O9n2l7V93iZ8AHJE2U1F/SycBoiletWTdwgFhHTqe49PIkxT/pO4HWyd7LgYMoLmfcBfyo6r7/CHxJxauQLo6Il4C/B24CVlA8++3ojWTtHf8Q4CFJr1Bc978gIpa2s69fAIuB+4CvR8TPWxsi4kGK8Hk0Ijp1mSeKVzzdGxGv1Whrpjg7ujHVvZh0mSkingSuo7ge/zzFpbQHO3PMGl6mmHt4KL0S6jfAAuCzqf27wCyKie1H+fPH6MsUk9prKR7PH5TaplNc8llB8fv/De2I4iW844AxwDPACxSP9bapy+Vpf89QPDHoTFA/ro3fB3J9J+7TWs/qVM9nKULw88C4iHihs/uw9ilNJpn1eZLmAD+IiJsaXUu9SBpJ8Q98QBuXJc06zXMgZkC6zHIQxTV/M+sEX8KyPk/SNOBe4MKIeLnR9Zj1Fr6EZWZmWXwGYmZmWfrUHMj2228fI0eObHQZZma9yrx5816IiOr3bPWtABk5ciTNzc2NLsPMrFeRVPOl7b6EZWZmWRwgZmaWxQFiZmZZ+tQciJlZrjfffJOWlhZef/31RpdSNwMHDqSpqYkBA9r6LrWNOUDMzDqhpaWFbbbZhpEjR1L7u716t4hg9erVtLS0MGrUqE7dx5ewzMw64fXXX2fo0KHvyvAAkMTQoUM36QzLAWJm1knv1vBotanjc4CYmVkWB4iZWS8hidNOO23D+vr16xk2bBjjxo0D4Pnnn2fcuHEccMABjB49mhNOOAGAZcuWMWjQIMaMGbPhNn369C7X40l0M7NeYquttmLBggW89tprDBo0iNmzZ7PLLu98xftXvvIVjj76aC644AIAnnjiiQ1tu+++O/Pnz+/WenwGYmbWi5xwwgncddddAMyYMYNTTz11Q9vKlStpamrasL7//vvXtRafgZiZbaILL4RufjLPmDFwfSe+sPeUU07hiiuuYNy4cTzxxBNMnjyZX/7ylwCce+65nHzyydx4442MHTuWM888k+HDhwOwZMkSxowZs2E/N9xwA0cccUSXanaAmJn1Ivvvvz/Lli1jxowZG+Y4Wh177LEsXbqUe+65h7vvvpsDDzyQBQsWAPW5hOUAMTPbRJ05U6inE088kYsvvpi5c+eyevXqjdqGDBnCxIkTmThxIuPGjeOBBx7g4IMPrksdngMxM+tlJk+ezGWXXcZ+++230fY5c+awbt06AF5++WWWLFnCiBEj6laHz0DMzHqZpqYmzj///D/bPm/ePM477zz69+/P22+/zdlnn80hhxzCsmXL/mwOZPLkyTX3sSn61HeiVyqV8BdKmVmOp556ir333rvRZdRdrXFKmhcRleq+voRlZmZZHCBmZpbFAWJm1knv9kv+mzo+B4iZWScMHDiQ1atXv2tDpPX7QAYOHNjp+/hVWGZmndDU1ERLSwurVq1qdCl10/qNhJ3lADEz64QBAwZ0+pv6+gpfwjIzsywOEDMzy9LQAJF0nKSnJS2WdEmN9i0l3Z7aH5I0sqp9hKRXJF3cUzWbmVmhYQEiqR/wbeB4YDRwqqTRVd3OAtZGxB7AN4Brqtr/Gbi73rWamdmfa+QZyKHA4ohYGhFvALcB46v6jAempeU7gaOUvvVd0gTgGWBhD9VrZmYljQyQXYDlpfWWtK1mn4hYD7wEDJW0NfAF4PKODiLpHEnNkprfzS+/MzPrab11En0K8I2IeKWjjhExNSIqEVEZNmxY/SszM+sjGvk+kBXArqX1prStVp8WSf2BbYHVwGHASZKuBbYD3pb0ekTcWP+yzcwMGhsgjwB7ShpFERSnABOr+swEJgG/Bk4C5kTxOQIbvshX0hTgFYeHmVnPaliARMR6SecBs4B+wC0RsVDSFUBzRMwEbgZulbQYWEMRMmZmthnwF0qZmVm7/IVSZmbWrRwgZmaWxQFiZmZZHCBmZpbFAWJmZlkcIGZmlsUBYmZmWRwgZmaWxQFiZmZZHCBmZpbFAWJmZlkcIGZmlsUBYmZmWRwgZmaWxQFiZmZZHCBmZpbFAWJmZlkcIGZmlsUBYmZmWRwgZmaWxQFiZmZZHCBmZpbFAWJmZlkcIGZmlsUBYmZmWRwgZmaWxQFiZmZZHCBmZpbFAWJmZlkcIGZmlqWhASLpOElPS1os6ZIa7VtKuj21PyRpZNp+tKR5kv47/fyrnq7dzKyva1iASOoHfBs4HhgNnCppdFW3s4C1EbEH8A3gmrT9BeBjEbEfMAm4tWeqNjOzVo08AzkUWBwRSyPiDeA2YHxVn/HAtLR8J3CUJEXEYxHxbNq+EBgkacseqdrMzIDGBsguwPLSekvaVrNPRKwHXgKGVvX5BPBoRPypTnWamVkN/RtdQFdI2ofistYx7fQ5BzgHYMSIET1UmZnZu18jz0BWALuW1pvStpp9JPUHtgVWp/Um4MfA6RGxpK2DRMTUiKhERGXYsGHdWL6ZWd/WyAB5BNhT0ihJWwCnADOr+sykmCQHOAmYExEhaTvgLuCSiHiwxyo2M7MNGhYgaU7jPGAW8BRwR0QslHSFpBNTt5uBoZIWAxcBrS/1PQ/YA/iKpPnptkMPD8HMrE9TRDS6hh5TqVSiubm50WWYmfUqkuZFRKV6u9+JbmZmWRwgZmaWxQFiZmZZHCBmZpbFAWJmZlkcIGZmlsUBYmZmWRwgZmaWxQFiZmZZHCBmZpbFAWJmZlkcIGZmlsUBYmZmWRwgZmaWxQFiZmZZHCBmZpbFAWJmZlkcIGZmlsUBYmZmWRwgZmaWxQFiZmZZHCBmZpbFAWJmZlkcIGZmlsUBYmZmWRwgZmaWpd0AkXRaafkvq9rOq1dRZma2+evoDOSi0vINVW2Tu7kWMzPrRToKELWxXGvdzMz6kI4CJNpYrrVuZmZ9SP8O2veS9ATF2cbuaZm0vltdKzMzs81aRwGydz0PLuk44JtAP+CmiLi6qn1LYDpwMLAaODkilqW2LwJnAW8B50fErHrWamZmG2s3QCLi9+V1SUOB/w38ISLmdeXAkvoB3waOBlqARyTNjIgnS93OAtZGxB6STgGuAU6WNBo4BdgHGA7cK+kDEfFWV2oyM7PO6+hlvD+VtG9a3hlYQPHqq1slXdjFYx8KLI6IpRHxBnAbML6qz3hgWlq+EzhKktL22yLiTxHxDLA47c/MzHpIR5PooyJiQVo+E5gdER8DDqPrL+PdBVheWm9J22r2iYj1wEvA0E7eFwBJ50hqltS8atWqLpZsZmatOgqQN0vLRwE/A4iIl4G361VUd4qIqRFRiYjKsGHDGl2Omdm7RkeT6MslfYbiGf5BwD0AkgYBA7p47BXArqX1prStVp8WSf2BbSkm0ztzXzMzq6OOzkDOopioPoPiFVAvpu1/AfxbF4/9CLCnpFGStqCYFJ9Z1WcmMCktnwTMiYhI20+RtKWkUcCewMNdrMfMzDZBR6/C+iPw6Rrb7wfu78qBI2J9+jytWRQv470lIhZKugJojoiZwM0UE/aLgTUUIUPqdwfwJLAeONevwDIz61kqntC30ShVnxFsJCJO7PaK6qhSqURzc3OjyzAz61UkzYuISvX2juZADqd4tdMM4CH8+VdmZpZ0FCA7UbzR71RgInAXMCMiFta7MDMz27y1O4keEW9FxD0RMYli4nwxMNffBWJmZh2dgbR+HtVHKc5CRgLfAn5c37LMzGxz126ASJoO7EvxBsLLS+9KNzOzPq6jM5DTgFeBC4Dzi4+hAorJ9IiI99WxNjMz24x19D6Qjt5oaGZmfZQDwszMsjhAzMwsiwPEzMyyOEDMzCyLA8TMzLI4QMzMLIsDxMzMsjhAzMwsiwPEzMyyOEDMzCyLA8TMzLI4QMzMLIsDxMzMsjhAzMwsiwPEzMyyOEDMzCyLA8TMzLI4QMzMLIsDxMzMsjhAzMwsiwPEzMyyOEDMzCyLA8TMzLI0JEAkDZE0W9Ki9HNwG/0mpT6LJE1K294r6S5Jv5W0UNLVPVu9mZlB485ALgHui4g9gfvS+kYkDQEuAw4DDgUuKwXN1yNiL+BA4C8lHd8zZZuZWatGBch4YFpangZMqNHnWGB2RKyJiLXAbOC4iFgXEfcDRMQbwKNAUw/UbGZmJY0KkB0jYmVafg7YsUafXYDlpfWWtG0DSdsBH6M4izEzsx7Uv147lnQvsFONpkvLKxERkiJj//2BGcC3ImJpO/3OAc4BGDFixKYexszM2lC3AImIsW21SXpe0s4RsVLSzsAfa3RbARxZWm8C5pbWpwKLIuL6DuqYmvpSqVQ2OajMzKy2Rl3CmglMSsuTgJ/U6DMLOEbS4DR5fkzahqSvAtsCF/ZArWZmVkOjAuRq4GhJi4CxaR1JFUk3AUTEGuBK4JF0uyIi1khqorgMNhp4VNJ8SWc3YhBmZn2ZIvrOVZ1KpRLNzc2NLsPMrFeRNC8iKtXb/U50MzPL4gAxM7MsDhAzM8viADEzsywOEDMzy+IAMTOzLA4QMzPL4gAxM7MsDhAzM8viADEzsywOEDMzy+IAMTOzLA4QMzPL4gAxM7MsDhAzM8viADEzsywOEDMzy+IAMTOzLA4QMzPL4gAxM7MsDhAzM8viADEzsywOEDMzy+IAMTOzLA4QMzPL4gAxM7MsDhAzM8viADEzsywOEDMzy+IAMTOzLA4QMzPL0pAAkTRE0mxJi9LPwW30m5T6LJI0qUb7TEkL6l+xmZlVa9QZyCXAfRGxJ3BfWt+IpCHAZcBhwKHAZeWgkfRx4JWeKdfMzKo1KkDGA9PS8jRgQo0+xwKzI2JNRKwFZgPHAUjaGrgI+GoP1GpmZjU0KkB2jIiVafk5YMcafXYBlpfWW9I2gCuB64B1HR1I0jmSmiU1r1q1qgslm5lZWf967VjSvcBONZouLa9EREiKTdjvGGD3iPgHSSM76h8RU4GpAJVKpdPHMTOz9tUtQCJibFttkp6XtHNErJS0M/DHGt1WAEeW1puAucDhQEXSMor6d5A0NyKOxMzMekyjLmHNBFpfVTUJ+EmNPrOAYyQNTpPnxwCzIuI7ETE8IkYCHwJ+5/AwM+t5jQqQq4GjJS0CxqZ1JFUk3QQQEWso5joeSbcr0jYzM9sMKKLvTAtUKpVobm5udBlmZr2KpHkRUane7neim5lZFgeImZllcYCYmVkWB4iZmWVxgJiZWRYHiJmZZXGAmJlZFgeImZllcYCYmVkWB4iZmWVxgJiZWRYHiJmZZXGAmJlZFgeImZllcYCYmVkWB4iZmWVxgJiZWRYHiJmZZXGAmJlZFgeImZllcYCYmVkWB4iZmWVxgJiZWRYHiJmZZVFENLqGHiNpFfD7RtexibYHXmh0ET3MY+4bPObe4/0RMax6Y58KkN5IUnNEVBpdR0/ymPsGj7n38yUsMzPL4gAxM7MsDpDN39RGF9AAHnPf4DH3cp4DMTOzLD4DMTOzLA4QMzPL4gDZDEgaImm2pEXp5+A2+k1KfRZJmlSjfaakBfWvuOu6MmZJ75V0l6TfSloo6eqerX7TSDpO0tOSFku6pEb7lpJuT+0PSRpZavti2v60pGN7su6uyB2zpKMlzZP03+nnX/V07Tm68hin9hGSXpF0cU/V3C0iwrcG34BrgUvS8iXANTX6DAGWpp+D0/LgUvvHgR8ACxo9nnqPGXgv8JHUZwvgl8DxjR5TG+PsBywBdku1Pg6Mrurz98C/pOVTgNvT8ujUf0tgVNpPv0aPqc5jPhAYnpb3BVY0ejz1HG+p/U7gP4CLGz2eTbn5DGTzMB6YlpanARNq9DkWmB0RayJiLTAbOA5A0tbARcBXe6DW7pI95ohYFxH3A0TEG8CjQFMP1JzjUGBxRCxNtd5GMfay8u/iTuAoSUrbb4uIP0XEM8DitL/NXfaYI+KxiHg2bV8IDJK0ZY9Una8rjzGSJgDPUIy3V3GAbB52jIiVafk5YMcafXYBlpfWW9I2gCuB64B1dauw+3V1zABI2g74GHBfPYrsBh2OodwnItYDLwFDO3nfzVFXxlz2CeDRiPhTnersLtnjTU/+vgBc3gN1drv+jS6gr5B0L7BTjaZLyysREZI6/dpqSWOA3SPiH6qvqzZavcZc2n9/YAbwrYhYmlelbY4k7QNcAxzT6FrqbArwjYh4JZ2Q9CoOkB4SEWPbapP0vKSdI2KlpJ2BP9botgI4srTeBMwFDgcqkpZRPJ47SJobEUfSYHUcc6upwKKIuL4byq2XFcCupfWmtK1Wn5YUitsCqzt5381RV8aMpCbgx8DpEbGk/uV2WVfGexhwkqRrge2AtyW9HhE31r/sbtDoSRjfAuCf2HhC+doafYZQXCcdnG7PAEOq+oyk90yid2nMFPM9PwTe0+ixdDDO/hST/6N4Z4J1n6o+57LxBOsdaXkfNp5EX0rvmETvypi3S/0/3uhx9MR4q/pMoZdNoje8AN8Cimu/9wGLgHtL/yQrwE2lfpMpJlIXA2fW2E9vCpDsMVM8wwvgKWB+up3d6DG1M9YTgN9RvFLn0rTtCuDEtDyQ4hU4i4GHgd1K97003e9pNtNXmnXnmIEvAa+WHtf5wA6NHk89H+PSPnpdgPijTMzMLItfhWVmZlkcIGZmlsUBYmZmWRwgZmaWxQFiZmZZHCBmGSS9JWl+6TYyYx8TJI3u/urMeobfiW6W57WIGNPFfUwAfgo82dk7SOofxWcpmTWcz0DMuomkgyX9In2Pxaz0ES1I+pSkRyQ9LumH6ftMPgicCPxTOoPZXdJcSZV0n+3Tx9Mg6Yz0XS9zgPskbSXpFkkPS3pM0vjUb5+0bb6kJyTt2ZjfhPUVDhCzPINKl69+LGkAcANwUkQcDNwCXJX6/igiDomIAyjePX9WRPwKmAl8LiLGRMef+XRQ2veHKd6dPiciDgU+QhFCWwGfBr6ZzowqFJ8Ka1Y3voRllmejS1iS9qX4AqTZ6VNV+wGtH1e/r6SvUnzO09bArIzjzY6INWn5GODE0rfXDQRGAL8GLk0fRvijiFiUcRyzTnOAmHUPAQsj4vAabd8DJkTE45LOYONPGC5bzztXBQZWtb1adaxPRMTTVX2ekvQQ8FHgZ5L+NiLmdH4IZpvGl7DMusfTwDBJhwNIGpC+0wJgG2Blusz1f0v3eTm1tVoGHJyWT2rnWLOAz5S+0e7A9HM3YGlEfAv4CbB/l0Zk1gEHiFk3iOKrTE8CrpH0OMWnyH4wNX8ZeAh4EPht6W63AZ9LE+G7A18H/k7SY8D27RzuSmAA8ISkhWkd4G+ABZLmU1xOm94tgzNrgz+N18zMsvgMxMzMsjhAzMwsiwPEzMyyOEDMzCyLA8TMzLI4QMzMLIsDxMzMsvx/CWgSFTWMI2EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnTtvHQb8Ms6"
      },
      "source": [
        "# Import the attack\n",
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "logits_model = tf.keras.Model(model.input,model.layers[-1].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0IrRrwp8Ms_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "cc8adf76-cb5c-46fa-f4a3-45aa0fc8fdfd"
      },
      "source": [
        "# Get a random test case\n",
        "ra = np.random.randint(X_test.shape[0])\n",
        "print (\"Index:\",ra)\n",
        "example_vals = X_test[ra, :]\n",
        "example_labels = Y_test[ra]\n",
        "#example_labels = Y_attack[ra]\n",
        "\n",
        "example_vals = tf.convert_to_tensor(example_vals.reshape((1, 77)))\n",
        "example_labels = np.reshape(example_labels, (1,)).astype('int64')\n",
        "\n",
        "print (\"Values:\",example_vals)\n",
        "print (\"Label:\", example_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e3c9f0a92b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get a random test case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Index:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexample_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexample_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mra\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnjFgrdP8MtD"
      },
      "source": [
        "# Non-Targeted Attack\n",
        "\n",
        "epsilon = 0.1\n",
        "\n",
        "adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, targeted=False)\n",
        "adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n",
        "\n",
        "print (\"Original Label:\" , example_labels)\n",
        "print (\"FGSM Label:\", np.argmax(adv_example_untargeted_label_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze9tzgi88MtM"
      },
      "source": [
        "# Batch run on all test data\n",
        "\n",
        "CLASS_TO_CHANGE = 1 # 1 will make all true cases appear as false\n",
        "\n",
        "X_adv = np.zeros(X_test.shape)\n",
        "\n",
        "print (X_test.shape)\n",
        "for i in range(X_test.shape[0]):\n",
        "    current_class = Y_test[i]\n",
        "    #print(\"Class:\", current_class)\n",
        "    if current_class == CLASS_TO_CHANGE:\n",
        "        example_vals = X_test[i, :]\n",
        "        example_labels = Y_test[i]\n",
        "        example_vals = tf.convert_to_tensor(example_vals.reshape((1, 77)))\n",
        "        example_labels = np.reshape(example_labels, (1,)).astype('int64')\n",
        "        epsilon = 0.1\n",
        "        adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, targeted=False)\n",
        "        adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n",
        "    \n",
        "        X_adv[i,:] = adv_example_untargeted_label\n",
        "        X_test[i,:] = adv_example_untargeted_label\n",
        "        #print (example_labels, \"--->\", np.argmax(adv_example_untargeted_label_pred))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8Xs285k8MtR"
      },
      "source": [
        "## Multi-class Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2X6qnk98MtS"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_attack, test_size = 0.7, random_state = 42, stratify=Y_class)\n",
        "print (\"X_Train:\", X_train.shape)\n",
        "print (\"X_Test:\", X_test.shape)\n",
        "print (\"Y_Train:\", Y_train.shape)\n",
        "print (\"Y_Test:\", Y_test.shape)\n",
        "\n",
        "print(np.unique(Y_attack), len(np.unique(Y_attack)), Y_attack)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=[X_train.shape[1]]),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(np.unique(Y_attack))),\n",
        "    tf.keras.layers.Activation(tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss= 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, epochs=10, validation_split=0.2)\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd7PYfsP8MtW"
      },
      "source": [
        "# Import the attack\n",
        "from cleverhans.future.tf2.attacks import fast_gradient_method\n",
        "\n",
        "#The attack requires the model to ouput the logits\n",
        "logits_model = tf.keras.Model(model.input,model.layers[-1].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKONDuim8Mta"
      },
      "source": [
        "# Get a random test case\n",
        "ra = np.random.randint(X_test.shape[0])\n",
        "print (\"Index:\",ra)\n",
        "example_vals = X_test[ra, :]\n",
        "#example_labels = Y_test[ra]\n",
        "example_labels = Y_attack[ra]\n",
        "\n",
        "example_vals = tf.convert_to_tensor(example_vals.reshape((1, 77)))\n",
        "example_labels = np.reshape(example_labels, (1,)).astype('int64')\n",
        "\n",
        "print (\"Values:\",example_vals)\n",
        "print (\"Label:\", example_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPRagwZl8Mtc"
      },
      "source": [
        "# Non-Targeted Attack\n",
        "\n",
        "epsilon = 0.1\n",
        "\n",
        "adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, targeted=False)\n",
        "adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n",
        "\n",
        "print (\"Original Label:\" , example_labels)\n",
        "print (\"FGSM Label:\", np.argmax(adv_example_untargeted_label_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NsnwHJo8Mtx"
      },
      "source": [
        "text_labels = []\n",
        "text_labels.append(\"Benign\")\n",
        "text_labels.append(\"Bot\")\n",
        "text_labels.append(\"DDoS GoldenEye\")\n",
        "text_labels.append(\"DDoS Hulk\")\n",
        "text_labels.append(\"DDoS Slowhttptest\")\n",
        "text_labels.append(\"slowloris\")\n",
        "text_labels.append(\"FTP-Patator\")\n",
        "text_labels.append(\"Heartbleed\")\n",
        "text_labels.append(\"Infiltration\")\n",
        "#text_labels.append(\"Label\")\n",
        "text_labels.append(\"SSH-Patator\")\n",
        "text_labels.append(\"Web Attack - Brute Force\")\n",
        "text_labels.append(\"Web Attack - Sql Injection\")\n",
        "text_labels.append(\"Web Attack - XSS\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz64szxP8Mth"
      },
      "source": [
        "# Batch run on all test data\n",
        "mserrors = []\n",
        "graph_labels = []\n",
        "\n",
        "for all_classes in range(15):\n",
        "  CLASS_TO_CHANGE = all_classes # 0 will change all that have 0 to some other untargeted class\n",
        "  X_adv = np.zeros(X_test.shape)\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  print (X_test.shape)\n",
        "  for i in range(X_test.shape[0]):\n",
        "      current_class = Y_test[i]\n",
        "      #print(\"Class:\", current_class)\n",
        "      if current_class == CLASS_TO_CHANGE:\n",
        "          example_vals = X_test[i, :]\n",
        "          example_labels = Y_test[i]\n",
        "          example_vals = tf.convert_to_tensor(example_vals.reshape((1, 77)))\n",
        "          example_labels = np.reshape(example_labels, (1,)).astype('int64')\n",
        "          epsilon = 0.1\n",
        "          adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, targeted=False)\n",
        "          adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n",
        "\n",
        "          X_adv[i,:] = adv_example_untargeted_label\n",
        "          X_test[i,:] = adv_example_untargeted_label\n",
        "          #print (example_labels, \"--->\", np.argmax(adv_example_untargeted_label_pred))\n",
        "          \n",
        "          #find overall difference\n",
        "          error = (X_test - X_adv)\n",
        "          #print (error)\n",
        "          #find MeanSquaredError\n",
        "          mse = tf.reduce_mean(tf.square(error, name=\"mse\"))\n",
        "          mserrors.append(mse)\n",
        "          graph_labels.append(current_class)\n",
        "\n",
        "          \n",
        "          #print(mse)\n",
        "\n",
        "          # find difference in each feature\n",
        "\n",
        "          #print(example_vals)\n",
        "          for feature in range(77): \n",
        "            if (X_test[i][feature] != X_adv[i][feature]):\n",
        "              print(\"Example: {} Feature: {} + {} {}\".format(i, feature, X_test[i][feature], X_adv[i][feature]))\n",
        "\n",
        "            pass\n",
        "\n",
        "        \n",
        "\n",
        "  test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "  print('Test accuracy:', test_acc)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOso9J2EE9bq"
      },
      "source": [
        "print(np.array(graph_labels).shape)\n",
        "print(np.array(mserrors).shape)\n",
        "\n",
        "xplot = np.array(graph_labels)\n",
        "yplot = np.array(mserrors) \n",
        "\n",
        "plt.scatter(xplot, yplot)\n",
        "plt.xlabel('Class')\n",
        "xticks = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
        "plt.xticks(xticks,xticks)\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.title('Size of difference required to change original data to be recognised as another class')\n",
        "#plt.scatter(mserrors[1], mserrors[1])\n",
        "\n",
        "#plt.scatter(X[:9999, 0], X[:9999, 1], color='blue', alpha=0.4, label='Original Data')\n",
        "\n",
        "\n",
        "\n",
        "#plt.scatter(Xadv[:9999, 0], Xadv[:9999, 1], color='green', alpha=0.4, label='Adversarial Examples, Epsilon = 0.2')\n",
        "#plt.scatter(Xadv2[:9999, 0], Xadv2[:9999, 1], color='purple', alpha=0.4, label='Adversarial Examples, Epsilon = 0.5')\n",
        "#plt.scatter(X[10000:, 0], X[10000:, 1], color='red', alpha=0.4, label='Original Data')\n",
        "#plt.scatter(Xadv[10000:, 0], Xadv[10000:, 1], color='orange', alpha=0.4, label='Adversarial Examples, Epsilon = 0.2')\n",
        "#plt.scatter(Xadv2[10000:, 0], Xadv2[10000:, 1], color='yellow', alpha=0.4, label='Adversarial Examples, Epsilon = 0.5')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH65_t8q8Mts"
      },
      "source": [
        "### Targeted Attack on the Multi-Class Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmkYdF1D8Mtt"
      },
      "source": [
        "epsilon = 0.1\n",
        "# The target value may have to be changed to work, some images are more easily missclassified as different labels\n",
        "target = 5\n",
        "target_label = np.reshape(target, (1,)).astype('int64') # Give target label proper size and dtype to feed through\n",
        "adv_example_untargeted_label = fast_gradient_method(logits_model, example_vals, epsilon, np.inf, y=target_label, targeted=True)\n",
        "adv_example_untargeted_label_pred = model.predict(adv_example_untargeted_label)\n",
        "\n",
        "print (\"Original Label:\" , example_labels)\n",
        "print (\"FGSM Label:\", np.argmax(adv_example_untargeted_label_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm-0RaMW8Mtw"
      },
      "source": [
        "## Further Actions\n",
        "\n",
        "This notebook shows how to perform FGSM against the CICIDS2017 dataset. Some points to consider for further work:\n",
        "\n",
        "* This mostly replicates what was in the IDS.py example. The added batch test at the end of each of the two methods will compromise a given class, re-insert the new adversarial features, and then re-test the classifier performance with these values. What is the perturbation in the adversarial cases? (Hint: Look at X_adv, and think how it should be used with X_test).\n",
        "* How may you study the decision boundaries of all features? (If we had 2 features then a scatter plot would work. If we reduce dimensionality using PCA then scatter plot works, but we lose original data. Parallel Co-ordinates could help here.) What is the expected range of values for a given class.\n",
        "* What value of epsilon is required to shift between classes? (For multi-class) Which classes can be most easily manipulated (this is essentially the same as asking which classes appear close in feature space).\n",
        "* Most examples of adversarial learning focus on images because of the weakness in human vision and the conversion of pixel intensity to numerical values for computation. In cases like this where the data is inherently numerical, how does an attacker 'disguise' their attack, and how does a 'defender' notice this (i.e., what correlations exist between features, and do adversarial examples contradict the expected correlations - is this the way to spot such cases?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNZUJYVM8Mt0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOwjuPgv7f5b"
      },
      "source": [
        "  #print(mserrors)\n",
        "\n",
        "  #print(min(mserrors))\n",
        "  print(\"Minimum MSE: {}\".format(min(mserrors)))\n",
        "  print(\"Maximum MSE: {}\".format(max(mserrors)))\n",
        "  print(\"Mean MSE: {}\".format((sum(mserrors)/len(mserrors))))\n",
        "\n",
        "  temp = min(mserrors) \n",
        "  res = [] \n",
        "  for idx in range(0, len(mserrors)): \n",
        "      if temp == mserrors[idx]: \n",
        "          res.append(idx) \n",
        "      \n",
        "  # Printing result \n",
        "  print(\"The Positions of minimum element : \" + str(res)) \n",
        "  minindex = res\n",
        "\n",
        "\n",
        "  temp = max(mserrors) \n",
        "  res = [] \n",
        "  for idx in range(0, len(mserrors)): \n",
        "      if temp == mserrors[idx]: \n",
        "          res.append(idx) \n",
        "      \n",
        "  # Printing result \n",
        "  print(\"The Positions of maximum element : \" + str(res)) \n",
        "  maxindex = res\n",
        "\n",
        "\n",
        "  #show the minimum perturbations\n",
        "  print(\"Minimum Perturbation-------------\")\n",
        "  print(X_test[minindex])\n",
        "  orig_label = int(Y_test[minindex])\n",
        "  print(\"Original Label: {}\".format(text_labels[orig_label]))\n",
        "\n",
        "\n",
        "  #show the maximum perturbations\n",
        "  print(\"Maximum Perturbation-------------\")\n",
        "  print(X_test[maxindex])\n",
        "  orig_label = int(Y_test[maxindex])\n",
        "  print(\"Original Label: {}\".format(text_labels[orig_label]))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}